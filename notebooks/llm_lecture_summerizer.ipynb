{"cells":[{"cell_type":"markdown","metadata":{"id":"MntmiANZCk2L"},"source":["# Summary of Lecture Video\n","\n","\n","\n","\n","### Reference\n","\n","[GenAI 2024 course at ntu](https://speech.ee.ntu.edu.tw/~hylee/genai/2024-spring.php)"]},{"cell_type":"markdown","metadata":{"id":"voEioD2DCoeq"},"source":["# Part1 - Preparation"]},{"cell_type":"markdown","metadata":{"id":"mSccLtt234Pm"},"source":["## The lecture video provided for this assignment"]},{"cell_type":"markdown","metadata":{"id":"SgHVz9WF4Vfp"},"source":["(1) For ease of processing, it has already been converted to a MP3 file.\n","\n","(2) If you would like to view the original video, the link is here:\n","\n","- 李琳山教授 信號與人生 (2023)\n","\n","  - https://www.youtube.com/watch?v=MxoQV4M0jY8\n","\n","\n","(3) Since the original lecture video is quite long, we have edited the segment from 1:43:24 to 2:00:49 to use for this assignment."]},{"cell_type":"markdown","metadata":{"id":"gdoLJZE33oCD"},"source":["## Install all necessary packages and import them"]},{"cell_type":"markdown","metadata":{"id":"HREsIZV33yDy"},"source":["The following code block takes about **150** seconds to run, but it may vary slightly depending on the condition of Colab."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":194385,"status":"ok","timestamp":1720230587082,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"119AJB_AAhJl","outputId":"a2fe8211-c955-4249-b7bd-76dc09084b82"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting srt==3.5.3\n","  Downloading srt-3.5.3.tar.gz (28 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: srt\n","  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=e6115ca348c8098edb531f253b2651ad8600498519da4e3e16ad032e977936f0\n","  Stored in directory: /root/.cache/pip/wheels/d7/31/a1/18e1e7e8bfdafd19e6803d7eb919b563dd11de380e4304e332\n","Successfully built srt\n","Installing collected packages: srt\n","Successfully installed srt-3.5.3\n","Collecting datasets==2.20.0\n","  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (3.15.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (1.25.2)\n","Collecting pyarrow>=15.0.0 (from datasets==2.20.0)\n","  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets==2.20.0)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (2.0.3)\n","Collecting requests>=2.32.2 (from datasets==2.20.0)\n","  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (4.66.4)\n","Collecting xxhash (from datasets==2.20.0)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets==2.20.0)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (0.23.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.20.0) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.20.0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.20.0) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.20.0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.20.0) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.20.0) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.20.0) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets==2.20.0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==2.20.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets==2.20.0) (2024.6.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.20.0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.20.0) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.20.0) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.20.0) (1.16.0)\n","Installing collected packages: xxhash, requests, pyarrow, dill, multiprocess, datasets\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-16.1.0 requests-2.32.3 xxhash-3.4.1\n","Collecting DateTime==5.5\n","  Downloading DateTime-5.5-py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting zope.interface (from DateTime==5.5)\n","  Downloading zope.interface-6.4.post2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (247 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.8/247.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from DateTime==5.5) (2023.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->DateTime==5.5) (67.7.2)\n","Installing collected packages: zope.interface, DateTime\n","Successfully installed DateTime-5.5 zope.interface-6.4.post2\n","Collecting OpenCC==1.1.7\n","  Downloading OpenCC-1.1.7-cp310-cp310-manylinux1_x86_64.whl (779 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.8/779.8 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: OpenCC\n","Successfully installed OpenCC-1.1.7\n","Requirement already satisfied: opencv-contrib-python==4.8.0.76 in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-contrib-python==4.8.0.76) (1.25.2)\n","Requirement already satisfied: opencv-python==4.8.0.76 in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python==4.8.0.76) (1.25.2)\n","Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless==4.10.0.84) (1.25.2)\n","Collecting openpyxl==3.1.4\n","  Downloading openpyxl-3.1.4-py2.py3-none-any.whl (251 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.4/251.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl==3.1.4) (1.1.0)\n","Installing collected packages: openpyxl\n","  Attempting uninstall: openpyxl\n","    Found existing installation: openpyxl 3.1.5\n","    Uninstalling openpyxl-3.1.5:\n","      Successfully uninstalled openpyxl-3.1.5\n","Successfully installed openpyxl-3.1.4\n","Collecting openai==1.35.3\n","  Downloading openai-1.35.3-py3-none-any.whl (327 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.35.3) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.35.3) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai==1.35.3)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.35.3) (2.8.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.35.3) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.35.3) (4.66.4)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.35.3) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.35.3) (3.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.35.3) (1.2.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.35.3) (2024.6.2)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.35.3)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.35.3)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.35.3) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.35.3) (2.20.0)\n","Installing collected packages: h11, httpcore, httpx, openai\n","Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.3\n","Collecting git+https://github.com/openai/whisper.git@ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n","  Cloning https://github.com/openai/whisper.git (to revision ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab) to /tmp/pip-req-build-4jia8620\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-4jia8620\n","  Running command git rev-parse -q --verify 'sha^ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab'\n","  Running command git fetch -q https://github.com/openai/whisper.git ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n","  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n","Collecting tiktoken (from openai-whisper==20231117)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.15.4)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.32.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch->openai-whisper==20231117)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.6.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n","Building wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802823 sha256=00aa9004a477a9ba5009b147fa66fcbe5a52e95c38c8172e44e634943093362d\n","  Stored in directory: /root/.cache/pip/wheels/7b/c0/95/fabd0871b678365ff6200dd56ed9e951a97d51f22ae741c264\n","Successfully built openai-whisper\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, openai-whisper\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 openai-whisper-20231117 tiktoken-0.7.0\n","Requirement already satisfied: numpy==1.25.2 in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: soundfile==0.12.1 in /usr/local/lib/python3.10/dist-packages (0.12.1)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile==0.12.1) (1.16.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile==0.12.1) (2.22)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.1/163.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m717.3/717.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting anthropic==0.29.0\n","  Downloading anthropic-0.29.0-py3-none-any.whl (863 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m863.5/863.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic==0.29.0) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic==0.29.0) (1.7.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic==0.29.0) (0.27.0)\n","Collecting jiter<1,>=0.4.0 (from anthropic==0.29.0)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic==0.29.0) (2.8.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic==0.29.0) (1.3.1)\n","Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic==0.29.0) (0.19.1)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic==0.29.0) (4.12.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic==0.29.0) (3.7)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic==0.29.0) (1.2.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic==0.29.0) (2024.6.2)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic==0.29.0) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic==0.29.0) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic==0.29.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic==0.29.0) (2.20.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic==0.29.0) (0.23.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic==0.29.0) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic==0.29.0) (2023.6.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic==0.29.0) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic==0.29.0) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic==0.29.0) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic==0.29.0) (4.66.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic==0.29.0) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic==0.29.0) (2.0.7)\n","Installing collected packages: jiter, anthropic\n","Successfully installed anthropic-0.29.0 jiter-0.5.0\n"]}],"source":["# Install packages.\n","!pip install srt==3.5.3\n","!pip install datasets==2.20.0\n","!pip install DateTime==5.5\n","!pip install OpenCC==1.1.7\n","!pip install opencv-contrib-python==4.8.0.76\n","!pip install opencv-python==4.8.0.76\n","!pip install opencv-python-headless==4.10.0.84\n","!pip install openpyxl==3.1.4\n","!pip install openai==1.35.3\n","!pip install git+https://github.com/openai/whisper.git@ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n","!pip install numpy==1.25.2\n","!pip install soundfile==0.12.1\n","!pip install -q -U google-generativeai==0.7.0\n","!pip install anthropic==0.29.0"]},{"cell_type":"markdown","metadata":{"id":"hWqXz6C6omR9"},"source":["The following code block takes about **5** seconds to run, but it may vary slightly depending on the condition of Colab."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11297,"status":"ok","timestamp":1720230598371,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"JFwSa_x6C53S"},"outputs":[],"source":["# Import packages.\n","import whisper\n","import srt\n","import datetime\n","import time\n","import os\n","import re\n","import pathlib\n","import textwrap\n","import numpy as np\n","import soundfile as sf\n","from opencc import OpenCC\n","from tqdm import tqdm\n","from datasets import load_dataset\n","from openai import OpenAI\n","import google.generativeai as genai\n","import anthropic"]},{"cell_type":"markdown","metadata":{"id":"KFY6VDAyeooa"},"source":["## Download data"]},{"cell_type":"markdown","metadata":{"id":"zBROu_HfgF1J"},"source":["The code block below takes about **10** seconds to run, although there might be some slight variation depending on the state of Colab."]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240,"referenced_widgets":["5156fd14f58644368b148f9c73fff9cd","f68c91877bff4a259be366636404eadf","5089838937f6495a91dbe6059863ec63","c513022c9c12401297db6554dd5eeb50","7d46ac072d6c49ac950cdb58ec041ff4","7c4aca1d686642f3811f3dfd56cbe540","fd9fac39c4cb496288dfd100de847d20","90f0fa64343943d69a9ef53f266b3ae3","61d9a406fb0243fe8097e47455866818","45b0b5230ac444479157b04a351c1233","0f06d752ff9e46e289f50ade0c5c4465","9b157dc60086447fb0ef5867d3323d65","b0cf8b957b4e489398311db291cea3bd","e9717a562c2e4fb2ba8214be98b9dd3c","7f8f4823e20747e790e43b435516d9df","7eefe3fea7ae4de6915b903fafa082e0","298a20d5460445bcb4872fd1553e993d","840eabcc6ad14ad9bfb0d792e7d85846","be333f52c13e4491a18154677a735937","962ac1fb0ded40599389f65939df6e96","838bf0f29b244b55856d299bf93517f3","ccd92eb8d25b4b57a7faf2e7d9f5f182","636924e77e57421086b35f9b7f21ed5b","0a46661e01c549a0a1ee63121cd01bb6","dc278d61129d415fbaabf02bfe42e17e","48f6cc4b3f4340748ec19a59a0da2450","21715260b1154470820b63c3fad1e4f8","88dbe924dd564b32b6b282aa581d24e8","b6efa01705d7491a9cd7d9ff0868ec9c","f6702a21d61e478d920b5f4ed66e30a9","d8ba70dbc54a4959ac44edf58364f35b","898b1317b7ae4932b865a19b53322e35","13c8e2712bfd4dfaa359da46a1ccd9d5"]},"executionInfo":{"elapsed":3767,"status":"ok","timestamp":1720230602136,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"PAieqtY8evUJ","outputId":"924624bd-f83f-4f4a-fdce-f6c293c3cf2e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5156fd14f58644368b148f9c73fff9cd","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/305 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b157dc60086447fb0ef5867d3323d65","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/3.14M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"636924e77e57421086b35f9b7f21ed5b","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Load dataset.\n","dataset_name = \"kuanhuggingface/NTU-GenAI-2024-HW9\"\n","dataset = load_dataset(dataset_name)"]},{"cell_type":"markdown","metadata":{"id":"T1pN3dOGyrI-"},"source":["The code block below takes about **15** seconds to run, although there might be some slight variation depending on the state of Colab."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20545,"status":"ok","timestamp":1720230622679,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"E68E8Ej2isAX","outputId":"9f079fef-6978-4437-ed87-eadd363e2bba"},"outputs":[{"name":"stdout","output_type":"stream","text":["Now, we are going to transcribe the audio: 李琳山教授 信號與人生 (2023) (ntu-gen-ai-2024-hw9-16k.mp3).\n"]}],"source":["# Prepare audio.\n","input_audio = dataset[\"test\"][\"audio\"][0]\n","input_audio_name = input_audio[\"path\"]\n","input_audio_array = input_audio[\"array\"].astype(np.float32)\n","sampling_rate = input_audio[\"sampling_rate\"]\n","\n","print(f\"Now, we are going to transcribe the audio: 李琳山教授 信號與人生 (2023) ({input_audio_name}).\")"]},{"cell_type":"markdown","metadata":{"id":"vxTn1CfzDCXy"},"source":["# Part2 - Automatic Speech Recognition (ASR)\n","The function \"speech_recognition\" aims to convert audio to subtitle."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1720230622679,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"OmWjjLUGC9z3"},"outputs":[],"source":["def speech_recognition(model_name, input_audio, output_subtitle_path, decode_options, cache_dir=\"./\"):\n","    '''\n","        (1) Objective:\n","            - This function aims to convert audio to subtitle.\n","\n","        (2) Arguments:\n","\n","            - model_name (str):\n","                The name of the model. There are five model sizes, including tiny, base, small, medium, large-v3.\n","                For example, you can use 'tiny', 'base', 'small', 'medium', 'large-v3' to specify the model name.\n","                You can see 'https://github.com/openai/whisper' for more details.\n","\n","            - input_audio (Union[str, np.ndarray, torch.Tensor]):\n","                The path to the audio file to open, or the audio waveform\n","                - For example, if your input audio path is 'input.wav', you can use 'input.wav' to specify the input audio path.\n","                - For example, if your input audio array is 'audio_array', you can use 'audio_array' to specify the input audio array.\n","\n","            - output_subtitle_path (str):\n","                The path of the output subtitle file.\n","                For example, if you want to save the subtitle file as 'output.srt', you can use 'output.srt' to specify the output subtitle path.\n","\n","            - decode_options (dict):\n","                The options for decoding the audio file, including 'initial_prompt', 'prompt', 'prefix', 'temperature'.\n","                - initial_prompt (str):\n","                    Optional text to provide as a prompt for the first window. This can be used to provide, or\n","                    \"prompt-engineer\" a context for transcription, e.g. custom vocabularies or proper nouns\n","                    to make it more likely to predict those word correctly.\n","                    Default: None.\n","\n","                You can see \"https://github.com/openai/whisper/blob/main/whisper/decoding.py\" and \"https://github.com/openai/whisper/blob/main/whisper/transcribe.py\"\n","                for more details.\n","\n","                - temperature (float):\n","                    The temperature for sampling from the model. Higher values mean more randomness.\n","                    Default: 0.0\n","\n","            - cache_dir (str):\n","                The path of the cache directory for saving the model.\n","                For example, if you want to save the cache files in 'cache' directory, you can use 'cache' to specify the cache directory.\n","                Default: './'\n","\n","        (3) Example:\n","\n","            - If you want to use the 'base' model to convert 'input.wav' to 'output.srt' and save the cache files in 'cache' directory,\n","            you can call this function as follows:\n","\n","                speech_recognition(model_name='base', input_audio_path='input.wav', output_subtitle_path='output.srt', cache_dir='cache')\n","    '''\n","\n","    # Record the start time.\n","    start_time = time.time()\n","\n","    print(f\"=============== Loading Whisper-{model_name} ===============\")\n","\n","    # Load the model.\n","    model = whisper.load_model(name=model_name, download_root=cache_dir)\n","\n","    print(f\"Begin to utilize Whisper-{model_name} to transcribe the audio.\")\n","\n","    # Transcribe the audio.\n","    transcription = model.transcribe(audio=input_audio, language=decode_options[\"language\"], verbose=False,\n","                                     initial_prompt=decode_options[\"initial_prompt\"], temperature=decode_options[\"temperature\"])\n","\n","    # Record the end time.\n","    end_time = time.time()\n","\n","    print(f\"The process of speech recognition costs {end_time - start_time} seconds.\")\n","\n","    subtitles = []\n","    # Convert the transcription to subtitle and iterate over the segments.\n","    for i, segment in tqdm(enumerate(transcription[\"segments\"])):\n","\n","        # Convert the start time to subtitle format.\n","        start_time = datetime.timedelta(seconds=segment[\"start\"])\n","\n","        # Convert the end time to subtitle format.\n","        end_time = datetime.timedelta(seconds=segment[\"end\"])\n","\n","        # Get the subtitle text.\n","        text = segment[\"text\"]\n","\n","        # Append the subtitle to the subtitle list.\n","        subtitles.append(srt.Subtitle(index=i, start=start_time, end=end_time, content=text))\n","\n","    # Convert the subtitle list to subtitle content.\n","    srt_content = srt.compose(subtitles)\n","\n","    print(f\"\\n=============== Saving the subtitle to {output_subtitle_path} ===============\")\n","\n","    # Save the subtitle content to the subtitle file.\n","    with open(output_subtitle_path, \"w\", encoding=\"utf-8\") as file:\n","        file.write(srt_content)"]},{"cell_type":"markdown","metadata":{"id":"A3ZkyefXpvmh"},"source":["In the following block, you can modify your desired parameters and the path of input file."]},{"cell_type":"code","execution_count":6,"metadata":{"cellView":"form","executionInfo":{"elapsed":11,"status":"ok","timestamp":1720230622679,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"UULEr1GpDAl6"},"outputs":[],"source":["# @title Parameter Setting of Whisper { run: \"auto\" }\n","\n","''' In this block, you can modify your desired parameters and the path of input file. '''\n","\n","# The name of the model you want to use.\n","# For example, you can use 'tiny', 'base', 'small', 'medium', 'large-v3' to specify the model name.\n","# @markdown **model_name**: The name of the model you want to use.\n","model_name = \"medium\" # @param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v3\"]\n","\n","# Define the suffix of the output file.\n","# @markdown **suffix**: The output file name is \"output-{suffix}.* \", where .* is the file extention (.txt or .srt)\n","suffix = \"信號與人生\" # @param {type: \"string\"}\n","\n","# Path to the output file.\n","output_subtitle_path = f\"./output-{suffix}.srt\"\n","\n","# Path of the output raw text file from the SRT file.\n","output_raw_text_path = f\"./output-{suffix}.txt\"\n","\n","# Path to the directory where the model and dataset will be cached.\n","cache_dir = \"./\"\n","\n","# The language of the lecture video.\n","# @markdown **language**: The language of the lecture video.\n","language = \"zh\" # @param {type:\"string\"}\n","\n","# Optional text to provide as a prompt for the first window.\n","# @markdown **initial_prompt**: Optional text to provide as a prompt for the first window.\n","initial_prompt = \"請用中文\" #@param {type:\"string\"}\n","\n","# The temperature for sampling from the model. Higher values mean more randomness.\n","# @markdown  **temperature**: The temperature for sampling from the model. Higher values mean more randomness.\n","temperature = 0 # @param {type:\"slider\", min:0, max:1, step:0.1}"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1720230622680,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"TBhoPRKR9S4w"},"outputs":[],"source":["# Construct DecodingOptions\n","decode_options = {\n","    \"language\": language,\n","    \"initial_prompt\": initial_prompt,\n","    \"temperature\": temperature\n","}"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1720230622680,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"4SfQ5Xn-fjya","outputId":"4948185b-a41e-4188-bf5a-582679474f8e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Setting: (1) Model: whisper-medium (2) Language: zh (2) Initial Prompt: 請用繁體中文 (3) Temperature: 0\n","Transcribe 李琳山教授 信號與人生 (2023)\n"]}],"source":["# print message.\n","message = \"Transcribe 李琳山教授 信號與人生 (2023)\"\n","print(f\"Setting: (1) Model: whisper-{model_name} (2) Language: {language} (2) Initial Prompt: {initial_prompt} (3) Temperature: {temperature}\")\n","print(message)"]},{"cell_type":"markdown","metadata":{"id":"DxgZ2DNgpGlO"},"source":["The code block below takes about **90 (240)** seconds to run when using the **base (medium)** model and **a T4 GPU**, although there might be some slight variation depending on the state of Colab."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":203610,"status":"ok","timestamp":1720230826279,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"SOULGnw5RF6U","outputId":"d8b30f37-8048-4765-8086-bf24c6bb22a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["=============== Loading Whisper-medium ===============\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████████████████████████████████| 1.42G/1.42G [00:13<00:00, 114MiB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Begin to utilize Whisper-medium to transcribe the audio.\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 104500/104500 [02:51<00:00, 610.78frames/s]\n"]},{"name":"stdout","output_type":"stream","text":["The process of speech recognition costs 203.53660106658936 seconds.\n"]},{"name":"stderr","output_type":"stream","text":["370it [00:00, 199369.54it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","=============== Saving the subtitle to ./output-信號與人生.srt ===============\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Running ASR.\n","speech_recognition(model_name=model_name, input_audio=input_audio_array, output_subtitle_path=output_subtitle_path, decode_options=decode_options, cache_dir=cache_dir)"]},{"cell_type":"markdown","metadata":{"id":"BgmFtnti1qhU"},"source":["You can check the result of automatic speech recognition."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1720230826279,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"XeU54f5X1erZ","outputId":"8c56a191-4438-4bea-ca7d-5c63df3e950d"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","00:00:00,000 --> 00:00:04,000\n","每次說這個學問是做出來的\n","\n","2\n","00:00:06,000 --> 00:00:08,000\n","什麼意思?\n","\n","3\n","00:00:08,000 --> 00:00:12,000\n","要做才會獲得學問\n","\n","4\n","00:00:13,000 --> 00:00:16,000\n","你如果每天光是坐在那裡聽\n","\n","5\n","00:00:17,000 --> 00:00:20,000\n","學問很可能是左耳進右耳出的\n","\n","6\n","00:00:21,000 --> 00:00:23,000\n","你光是坐在那兒讀\n","\n","7\n","00:00:23,000 --> 00:00:26,000\n","學問可能從眼睛進入腦海之後就忘掉了\n","\n","8\n","00:00:26,000 --> 00:00:29,000\n","如何能夠學問在腦海裡面\n","\n","9\n","00:00:31,000 --> 00:00:33,000\n","真的變成你自己學問\n","\n","10\n","00:00:33,000 --> 00:00:35,000\n","就是要做\n","\n","11\n","00:00:36,000 --> 00:00:39,000\n","可能有很多同學有這個經驗\n","\n","12\n","00:00:39,000 --> 00:00:41,000\n","你如果去修某一門課\n","\n","13\n","00:00:41,000 --> 00:00:44,000\n","或者做某一個實驗\n","\n","14\n","00:00:44,000 --> 00:00:47,000\n","在期末就是要教一個final project\n","\n","15\n","00:00:48,000 --> 00:00:50,000\n","那個final project就是要你把\n","\n","16\n","00:00:51,000 --> 00:00:53,000\n","學到的很多東西\n","\n","17\n","00:00:53,000 --> 00:00:56,000\n","最後整合在你的final project裡面\n","\n","18\n","00:00:56,000 --> 00:00:58,000\n","最後做出來的時候\n","\n","19\n","00:00:58,000 --> 00:01:00,000\n","就是把它們都整合了\n","\n","20\n","00:01:00,000 --> 00:01:02,000\n","當你學期結束\n","\n","21\n","00:01:02,000 --> 00:01:04,000\n","真的把final project做完的時候\n","\n","22\n","00:01:04,000 --> 00:01:05,000\n","你會忽然發現\n","\n","23\n","00:01:05,000 --> 00:01:07,000\n","我真的學到很多東西\n","\n","24\n","00:01:07,000 --> 00:01:10,000\n","那就是做出來的學問\n","\n","25\n","00:01:10,000 --> 00:01:13,000\n","也許可以舉另外一個例子\n","\n","26\n","00:01:13,000 --> 00:01:16,000\n","就是你如果學了某一些很複雜的演算法\n","\n","27\n","00:01:16,000 --> 00:01:17,000\n","或者什麼\n","\n","28\n","00:01:17,000 --> 00:01:21,000\n","好像覺得那些不見得在你的腦海裡\n","\n","29\n","00:01:21,000 --> 00:01:24,000\n","可是後來老師出了個習題\n","\n","30\n","00:01:24,000 --> 00:01:26,000\n","那個習題教你寫一個很大的程式\n","\n","31\n","00:01:26,000 --> 00:01:28,000\n","要把所有東西都包進去\n","\n","32\n","00:01:28,000 --> 00:01:31,000\n","當你把這個程式寫完的時候你會發現\n","\n","33\n","00:01:31,000 --> 00:01:35,000\n","你忽然把演算法裡所有東西都弄通了\n","\n","34\n","00:01:35,000 --> 00:01:38,000\n","那就是學問是做出來的\n","\n","35\n","00:01:38,000 --> 00:01:40,000\n","所以我們永遠要記得\n","\n","36\n","00:01:40,000 --> 00:01:44,000\n","盡量多動手多做\n","\n","37\n","00:01:44,000 --> 00:01:46,000\n","在動手跟做的過程之中\n","\n","38\n","00:01:46,000 --> 00:01:49,000\n","學問才可以變成是自己的\n","\n","39\n","00:01:49,000 --> 00:01:51,000\n","同樣的情形就是說\n","\n","40\n","00:01:51,000 --> 00:01:57,000\n","很多時候這樣動手或者做的表現或者成績\n","\n","41\n","00:01:57,000 --> 00:02:00,000\n","沒有一個成績單上的數字\n","\n","42\n","00:02:00,000 --> 00:02:03,000\n","使得很多人覺得那不重要\n","\n","43\n","00:02:03,000 --> 00:02:07,000\n","很多人甚至覺得這門課要做final project\n","\n","44\n","00:02:07,000 --> 00:02:09,000\n","我就不修了太累了\n","\n","45\n","00:02:09,000 --> 00:02:12,000\n","或者說那門課需要怎麼樣怎麼樣太累\n","\n","46\n","00:02:12,000 --> 00:02:13,000\n","我就不要做了\n","\n","47\n","00:02:13,000 --> 00:02:17,000\n","而不知道其實那個才是讓你做的機會\n","\n","48\n","00:02:17,000 --> 00:02:19,000\n","然後可以學到最多\n","\n","49\n","00:02:19,000 --> 00:02:24,000\n","也就是說雖然很可能那麼辛苦的做很多事\n","\n","50\n","00:02:24,000 --> 00:02:27,000\n","沒有讓你獲得什麼具體成績\n","\n","51\n","00:02:27,000 --> 00:02:30,000\n","對你的overfitting可能沒有幫助\n","\n","52\n","00:02:30,000 --> 00:02:33,000\n","可是對你的全面學習是很有幫助\n","\n","53\n","00:02:33,000 --> 00:02:35,000\n","是該學的\n","\n","54\n","00:02:35,000 --> 00:02:38,000\n","那不要漏掉這些事\n","\n","55\n","00:02:38,000 --> 00:02:41,000\n","那這是我所說的\n","\n","56\n","00:02:41,000 --> 00:02:46,000\n","那這個課業內可以做的這些事\n","\n","57\n","00:02:46,000 --> 00:02:50,000\n","那剛才我們講到思考的時候\n","\n","58\n","00:02:50,000 --> 00:02:52,000\n","我覺得我漏掉一點\n","\n","59\n","00:02:52,000 --> 00:02:56,000\n","你如果修我的信號課你可能會發現\n","\n","60\n","00:02:56,000 --> 00:03:00,000\n","我上課沒講到一個數學式子的時候\n","\n","61\n","00:03:00,000 --> 00:03:02,000\n","我通常都不推他的\n","\n","62\n","00:03:02,000 --> 00:03:06,000\n","我是在解釋那個數學式子在說什麼話\n","\n","63\n","00:03:06,000 --> 00:03:08,000\n","同樣的呢\n","\n","64\n","00:03:08,000 --> 00:03:10,000\n","沒講到一個什麼什麼事情的時候\n","\n","65\n","00:03:10,000 --> 00:03:14,000\n","我通常就在解釋他在說什麼話\n","\n","66\n","00:03:14,000 --> 00:03:16,000\n","也就是說\n","\n","67\n","00:03:16,000 --> 00:03:20,000\n","我在講的就是我讀到特本那裡的時候\n","\n","68\n","00:03:20,000 --> 00:03:22,000\n","我心裡怎麼想的\n","\n","69\n","00:03:22,000 --> 00:03:28,000\n","也就是我在告訴同學如何這個讀書的時候\n","\n","70\n","00:03:28,000 --> 00:03:32,000\n","如何一面讀一面練習思考\n","\n","71\n","00:03:32,000 --> 00:03:37,000\n","那這個才是最重要的一件事\n","\n","72\n","00:03:37,000 --> 00:03:40,000\n","如何培養自己思考的能力\n","\n","73\n","00:03:40,000 --> 00:03:42,000\n","跟培養思考的習慣\n","\n","74\n","00:03:42,000 --> 00:03:46,000\n","我覺得最好的辦法就是讀書的時候\n","\n","75\n","00:03:46,000 --> 00:03:50,000\n","凡是讀到一個數學式子都去想一想\n","\n","76\n","00:03:50,000 --> 00:03:53,000\n","那個數學式子到底在說什麼\n","\n","77\n","00:03:53,000 --> 00:03:57,000\n","凡是讀到特本上講什麼就去想一想\n","\n","78\n","00:03:57,000 --> 00:03:59,000\n","那個到底在說什麼\n","\n","79\n","00:03:59,000 --> 00:04:03,000\n","你要真的了解他在說什麼的時候\n","\n","80\n","00:04:03,000 --> 00:04:06,000\n","你就用了很多思考的功夫\n","\n","81\n","00:04:06,000 --> 00:04:09,000\n","你就在練習自己思考的能力了\n","\n","82\n","00:04:09,000 --> 00:04:14,000\n","好 以上說的是課業內的部分\n","\n","83\n","00:04:14,000 --> 00:04:18,000\n","那當然除了課業內之外呢\n","\n","84\n","00:04:18,000 --> 00:04:21,000\n","還有一大堆是不在課業內的\n","\n","85\n","00:04:21,000 --> 00:04:24,000\n","那就是課業外的\n","\n","86\n","00:04:24,000 --> 00:04:27,000\n","課業外也有很多式的\n","\n","87\n","00:04:27,000 --> 00:04:33,000\n","那我們可以舉例來說\n","\n","88\n","00:04:33,000 --> 00:04:38,000\n","課業外有什麼可以學習的\n","\n","89\n","00:04:38,000 --> 00:04:42,000\n","那我通常把學習定義成為\n","\n","90\n","00:04:42,000 --> 00:04:43,000\n","什麼是學習\n","\n","91\n","00:04:43,000 --> 00:04:49,000\n","學習就是一種增長\n","\n","92\n","00:04:49,000 --> 00:04:53,000\n","一種進步\n","\n","93\n","00:04:53,000 --> 00:04:57,000\n","然後獲得快樂\n","\n","94\n","00:04:57,000 --> 00:05:00,000\n","這就是學習\n","\n","95\n","00:05:00,000 --> 00:05:03,000\n","所以即使是課業外的任何事情\n","\n","96\n","00:05:03,000 --> 00:05:05,000\n","只要你覺得是有增長的\n","\n","97\n","00:05:05,000 --> 00:05:07,000\n","是有進步的\n","\n","98\n","00:05:07,000 --> 00:05:08,000\n","讓你覺得快樂的\n","\n","99\n","00:05:08,000 --> 00:05:12,000\n","那應該就是值得學習的地方\n","\n","100\n","00:05:12,000 --> 00:05:16,000\n","那我們可以舉很多例子\n","\n","101\n","00:05:16,000 --> 00:05:20,000\n","譬如說很多同學喜歡打球\n","\n","102\n","00:05:20,000 --> 00:05:22,000\n","打球是不是學習\n","\n","103\n","00:05:22,000 --> 00:05:24,000\n","當然是\n","\n","104\n","00:05:24,000 --> 00:05:26,000\n","在打球中間有沒有增長\n","\n","105\n","00:05:26,000 --> 00:05:27,000\n","當然是\n","\n","106\n","00:05:27,000 --> 00:05:30,000\n","在打球中間有沒有增長\n","\n","107\n","00:05:30,000 --> 00:05:31,000\n","當然有增長\n","\n","108\n","00:05:31,000 --> 00:05:35,000\n","打球不只是對健康有增長\n","\n","109\n","00:05:35,000 --> 00:05:39,000\n","而且可能對於譬如說手腦協調\n","\n","110\n","00:05:39,000 --> 00:05:41,000\n","譬如說團隊精神\n","\n","111\n","00:05:41,000 --> 00:05:44,000\n","譬如說個人之間的互動\n","\n","112\n","00:05:44,000 --> 00:05:45,000\n","什麼可能都有幫助\n","\n","113\n","00:05:45,000 --> 00:05:47,000\n","所以打球當然是有增長的\n","\n","114\n","00:05:47,000 --> 00:05:50,000\n","那當然是很好的學習的機會\n","\n","115\n","00:05:50,000 --> 00:05:52,000\n","有人喜歡爬山\n","\n","116\n","00:05:52,000 --> 00:05:54,000\n","爬山是不是好的學習機會\n","\n","117\n","00:05:54,000 --> 00:05:55,000\n","當然是\n","\n","118\n","00:05:55,000 --> 00:05:57,000\n","這個我以前兩年前就講過很多\n","\n","119\n","00:05:57,000 --> 00:05:59,000\n","爬山可以學到很多的\n","\n","120\n","00:05:59,000 --> 00:06:02,000\n","那爬山當然是一種學習\n","\n","121\n","00:06:02,000 --> 00:06:03,000\n","有人說我不喜歡爬山\n","\n","122\n","00:06:03,000 --> 00:06:05,000\n","我去旅行好不好\n","\n","123\n","00:06:05,000 --> 00:06:07,000\n","旅行當然好\n","\n","124\n","00:06:07,000 --> 00:06:09,000\n","旅行可以增長見識\n","\n","125\n","00:06:09,000 --> 00:06:11,000\n","可以擴增事業\n","\n","126\n","00:06:11,000 --> 00:06:13,000\n","可以增加很多很多\n","\n","127\n","00:06:13,000 --> 00:06:14,000\n","當然是有進步的\n","\n","128\n","00:06:14,000 --> 00:06:16,000\n","所以當然是很好的學習\n","\n","129\n","00:06:16,000 --> 00:06:20,000\n","你凡是獲得快樂都是很好的事\n","\n","130\n","00:06:20,000 --> 00:06:23,000\n","那這些都值得下功夫去\n","\n","131\n","00:06:23,000 --> 00:06:25,000\n","把它看成是學習\n","\n","132\n","00:06:25,000 --> 00:06:27,000\n","都值得下功夫去做的\n","\n","133\n","00:06:27,000 --> 00:06:29,000\n","我們再講另外一系列\n","\n","134\n","00:06:29,000 --> 00:06:30,000\n","譬如說\n","\n","135\n","00:06:30,000 --> 00:06:34,000\n","有人說談戀愛是不是學習\n","\n","136\n","00:06:34,000 --> 00:06:37,000\n","談戀愛除了你在談戀愛上\n","\n","137\n","00:06:37,000 --> 00:06:39,000\n","會有收穫以外\n","\n","138\n","00:06:39,000 --> 00:06:41,000\n","本身也是有收穫的\n","\n","139\n","00:06:41,000 --> 00:06:44,000\n","因為讓你體驗到人跟人之間\n","\n","140\n","00:06:44,000 --> 00:06:45,000\n","的各種感覺\n","\n","141\n","00:06:45,000 --> 00:06:48,000\n","人跟人之間的各種期待等等\n","\n","142\n","00:06:48,000 --> 00:06:50,000\n","有沒有幫助\n","\n","143\n","00:06:50,000 --> 00:06:52,000\n","當然有幫助\n","\n","144\n","00:06:52,000 --> 00:06:54,000\n","對每一個人都是很好的學習\n","\n","145\n","00:06:54,000 --> 00:06:57,000\n","所以談戀愛當然是一件很好的事\n","\n","146\n","00:06:57,000 --> 00:07:00,000\n","有人會說那要靠緣分\n","\n","147\n","00:07:00,000 --> 00:07:02,000\n","沒有緣分沒有辦法\n","\n","148\n","00:07:02,000 --> 00:07:03,000\n","對不對\n","\n","149\n","00:07:03,000 --> 00:07:04,000\n","對\n","\n","150\n","00:07:04,000 --> 00:07:06,000\n","但是你不是一定要談戀愛嗎\n","\n","151\n","00:07:06,000 --> 00:07:07,000\n","你可以交朋友\n","\n","152\n","00:07:07,000 --> 00:07:10,000\n","交朋友是不是學習\n","\n","153\n","00:07:10,000 --> 00:07:11,000\n","當然是\n","\n","154\n","00:07:11,000 --> 00:07:13,000\n","交朋友也一樣\n","\n","155\n","00:07:13,000 --> 00:07:16,000\n","讓我們學到很多人際的互動\n","\n","156\n","00:07:16,000 --> 00:07:20,000\n","學到很多人跟人之間的溝通\n","\n","157\n","00:07:20,000 --> 00:07:22,000\n","人跟人之間的期待\n","\n","158\n","00:07:22,000 --> 00:07:24,000\n","人跟人之間的感覺\n","\n","159\n","00:07:24,000 --> 00:07:26,000\n","這都是交朋友之後學到的\n","\n","160\n","00:07:26,000 --> 00:07:28,000\n","對我們電機系的同學而言\n","\n","161\n","00:07:28,000 --> 00:07:31,000\n","你四周有一大群好同學\n","\n","162\n","00:07:31,000 --> 00:07:34,000\n","都是很好的交朋友的對象\n","\n","163\n","00:07:34,000 --> 00:07:36,000\n","你下一番功夫交朋友好不好\n","\n","164\n","00:07:36,000 --> 00:07:37,000\n","好\n","\n","165\n","00:07:37,000 --> 00:07:40,000\n","當然是有幫助的\n","\n","166\n","00:07:40,000 --> 00:07:42,000\n","另外當然我們可以舉很多\n","\n","167\n","00:07:42,000 --> 00:07:44,000\n","我們最現成的例子\n","\n","168\n","00:07:44,000 --> 00:07:47,000\n","譬如說我們的戲學會辦各種活動\n","\n","169\n","00:07:47,000 --> 00:07:49,000\n","那些活動有沒有幫助\n","\n","170\n","00:07:49,000 --> 00:07:50,000\n","當然有\n","\n","171\n","00:07:50,000 --> 00:07:54,000\n","我們舉例來講電業\n","\n","172\n","00:07:54,000 --> 00:07:57,000\n","你如果去參加某一個舞跳個舞\n","\n","173\n","00:07:57,000 --> 00:08:00,000\n","或者參加某個劇演個劇\n","\n","174\n","00:08:00,000 --> 00:08:01,000\n","有沒有幫助\n","\n","175\n","00:08:01,000 --> 00:08:02,000\n","當然有幫助\n","\n","176\n","00:08:02,000 --> 00:08:05,000\n","你在這中間一定發現有所增長\n","\n","177\n","00:08:05,000 --> 00:08:06,000\n","有所進步\n","\n","178\n","00:08:06,000 --> 00:08:09,000\n","那是為什麼有那麼多同學要去參加\n","\n","179\n","00:08:09,000 --> 00:08:13,000\n","就是因為發現那個確實是有增長有進步\n","\n","180\n","00:08:13,000 --> 00:08:15,000\n","有的人說\n","\n","181\n","00:08:15,000 --> 00:08:17,000\n","我不去跳那個舞\n","\n","182\n","00:08:17,000 --> 00:08:20,000\n","或者演那個劇\n","\n","183\n","00:08:20,000 --> 00:08:22,000\n","我做幕後的\n","\n","184\n","00:08:22,000 --> 00:08:25,000\n","譬如說是幕後的什麼規劃\n","\n","185\n","00:08:25,000 --> 00:08:29,000\n","或者說是什麼光舞的什麼軟體組\n","\n","186\n","00:08:29,000 --> 00:08:32,000\n","還是什麼服裝道具組\n","\n","187\n","00:08:32,000 --> 00:08:33,000\n","一樣\n","\n","188\n","00:08:33,000 --> 00:08:36,000\n","那個都是可以有獲得很多的增長\n","\n","189\n","00:08:36,000 --> 00:08:37,000\n","很多進步的\n","\n","190\n","00:08:37,000 --> 00:08:39,000\n","當然都是很有用的\n","\n","191\n","00:08:39,000 --> 00:08:42,000\n","都是很好的學習\n","\n","192\n","00:08:42,000 --> 00:08:47,000\n","那當然也包括電業以外的戲學會\n","\n","193\n","00:08:47,000 --> 00:08:50,000\n","其他的各種活動都一樣\n","\n","194\n","00:08:50,000 --> 00:08:55,000\n","也包括電機系以外的其他的校內\n","\n","195\n","00:08:55,000 --> 00:08:59,000\n","或者校外的各種活動幾乎都一樣\n","\n","196\n","00:08:59,000 --> 00:09:02,000\n","都可以讓人有所增長有所進步\n","\n","197\n","00:09:02,000 --> 00:09:04,000\n","都是很好的學習的機會\n","\n","198\n","00:09:04,000 --> 00:09:06,000\n","都是很好的學習\n","\n","199\n","00:09:06,000 --> 00:09:10,000\n","同樣的問題是這些東西都沒有考試\n","\n","200\n","00:09:10,000 --> 00:09:12,000\n","沒有成績\n","\n","201\n","00:09:12,000 --> 00:09:14,000\n","不能顯示在成績單上\n","\n","202\n","00:09:14,000 --> 00:09:18,000\n","因此對有一些同學會認為那個浪費時間\n","\n","203\n","00:09:18,000 --> 00:09:20,000\n","我不需要花時間去做那個\n","\n","204\n","00:09:20,000 --> 00:09:24,000\n","因為不影響我的overfitting的目標\n","\n","205\n","00:09:24,000 --> 00:09:26,000\n","裡面沒有這個嘛\n","\n","206\n","00:09:26,000 --> 00:09:28,000\n","具體成績沒有這些嘛\n","\n","207\n","00:09:28,000 --> 00:09:30,000\n","那不要這樣想\n","\n","208\n","00:09:30,000 --> 00:09:33,000\n","因為那些都非常的重要\n","\n","209\n","00:09:33,000 --> 00:09:36,000\n","都對你發展非常的重要\n","\n","210\n","00:09:36,000 --> 00:09:39,000\n","那我們說電機工程\n","\n","211\n","00:09:39,000 --> 00:09:41,000\n","今天的電機工程\n","\n","212\n","00:09:41,000 --> 00:09:44,000\n","很少什麼事情自己一個人可以做成功的\n","\n","213\n","00:09:44,000 --> 00:09:47,000\n","你必須跟很多人一起\n","\n","214\n","00:09:47,000 --> 00:09:50,000\n","才可能做成功一個非常重要的\n","\n","215\n","00:09:50,000 --> 00:09:52,000\n","有意義的工作\n","\n","216\n","00:09:52,000 --> 00:09:55,000\n","那當你跟一群人在一起做的時候\n","\n","217\n","00:09:55,000 --> 00:09:59,000\n","你必須學會如何進入一個團隊\n","\n","218\n","00:09:59,000 --> 00:10:03,000\n","從邊緣開始慢慢進入核心\n","\n","219\n","00:10:03,000 --> 00:10:06,000\n","從底層開始慢慢變成leader\n","\n","220\n","00:10:06,000 --> 00:10:09,000\n","然後如何可以推動你想做的事\n","\n","221\n","00:10:09,000 --> 00:10:13,000\n","如何變成可以做到你想做的事等等\n","\n","222\n","00:10:13,000 --> 00:10:15,000\n","這些都是很重要的\n","\n","223\n","00:10:15,000 --> 00:10:18,000\n","那我們通常稱這些東西\n","\n","224\n","00:10:18,000 --> 00:10:21,000\n","是所謂的soft skills\n","\n","225\n","00:10:21,000 --> 00:10:24,000\n","也就是軟實力\n","\n","226\n","00:10:24,000 --> 00:10:30,000\n","所謂軟實力就是硬實力以外的軟實力\n","\n","227\n","00:10:30,000 --> 00:10:34,000\n","硬實力是說你電子學的功力\n","\n","228\n","00:10:34,000 --> 00:10:36,000\n","數學的功力\n","\n","229\n","00:10:36,000 --> 00:10:40,000\n","這個城市能力這種是硬實力\n","\n","230\n","00:10:40,000 --> 00:10:45,000\n","軟實力我們主要就是講各種人際之間的\n","\n","231\n","00:10:45,000 --> 00:10:49,000\n","在人跟人之間的各種能力\n","\n","232\n","00:10:49,000 --> 00:10:54,000\n","包括溝通能力協調能力交朋友的能力\n","\n","233\n","00:10:54,000 --> 00:10:59,000\n","說服人的能力團隊精神領導能力等等\n","\n","234\n","00:10:59,000 --> 00:11:02,000\n","那些就是所謂的soft skills\n","\n","235\n","00:11:02,000 --> 00:11:04,000\n","重要不重要重要\n","\n","236\n","00:11:04,000 --> 00:11:07,000\n","你看到任何一個成功的電機工程師\n","\n","237\n","00:11:07,000 --> 00:11:09,000\n","他都有一堆這種\n","\n","238\n","00:11:09,000 --> 00:11:13,000\n","這個才是他成功的一個非常重要的關鍵\n","\n","239\n","00:11:13,000 --> 00:11:15,000\n","這種東西怎麼來\n","\n","240\n","00:11:15,000 --> 00:11:18,000\n","我們剛才講的各種課業外的\n","\n","241\n","00:11:18,000 --> 00:11:20,000\n","各種學習增長的機會\n","\n","242\n","00:11:20,000 --> 00:11:26,000\n","都可以幫助一個人塑造他的soft skills\n","\n","243\n","00:11:26,000 --> 00:11:30,000\n","是有少數人的這些soft skills是天生的\n","\n","244\n","00:11:30,000 --> 00:11:31,000\n","他天生就厲害\n","\n","245\n","00:11:31,000 --> 00:11:32,000\n","有沒有\n","\n","246\n","00:11:32,000 --> 00:11:33,000\n","有\n","\n","247\n","00:11:33,000 --> 00:11:35,000\n","但這種人畢竟沒那麼多\n","\n","248\n","00:11:35,000 --> 00:11:37,000\n","對很多人而言\n","\n","249\n","00:11:37,000 --> 00:11:42,000\n","他的soft skills是自己努力慢慢培養起來的\n","\n","250\n","00:11:42,000 --> 00:11:45,000\n","我剛才一開始前面講的那一段\n","\n","251\n","00:11:45,000 --> 00:11:49,000\n","我說我在進台大電機系以前\n","\n","252\n","00:11:49,000 --> 00:11:51,000\n","我幾乎不會交朋友\n","\n","253\n","00:11:51,000 --> 00:11:53,000\n","我不太會說話\n","\n","254\n","00:11:53,000 --> 00:11:57,000\n","我在讀大學的四年裡面改變我自己\n","\n","255\n","00:11:57,000 --> 00:12:02,000\n","讓我變成有很多這方面的能力的人\n","\n","256\n","00:12:02,000 --> 00:12:06,000\n","其實最重要就是我的很多soft skills\n","\n","257\n","00:12:06,000 --> 00:12:07,000\n","都是我自己培養\n","\n","258\n","00:12:07,000 --> 00:12:10,000\n","在讀台大電機系的四年裡面\n","\n","259\n","00:12:10,000 --> 00:12:14,000\n","獲得的非常多這方面的收穫的\n","\n","260\n","00:12:14,000 --> 00:12:18,000\n","那是為什麼我每次都要強調\n","\n","261\n","00:12:18,000 --> 00:12:21,000\n","這個東西有多麼重要\n","\n","262\n","00:12:21,000 --> 00:12:27,000\n","我之前曾經在幾年前的這個\n","\n","263\n","00:12:27,000 --> 00:12:31,000\n","信號與人生裡面有說到這一件事\n","\n","264\n","00:12:31,000 --> 00:12:33,000\n","我現在不要重複\n","\n","265\n","00:12:33,000 --> 00:12:36,000\n","但是我簡單的summarize\n","\n","266\n","00:12:36,000 --> 00:12:42,000\n","我說我們電機系的電機工程師的\n","\n","267\n","00:12:42,000 --> 00:12:45,000\n","一生career的發展\n","\n","268\n","00:12:45,000 --> 00:12:48,000\n","黃金實在是在什麼時候\n","\n","269\n","00:12:48,000 --> 00:12:52,000\n","我認為是在35歲到55歲\n","\n","270\n","00:12:52,000 --> 00:12:56,000\n","這20年是我們的黃金時代\n","\n","271\n","00:12:56,000 --> 00:12:58,000\n","在這以前當然更好\n","\n","272\n","00:12:58,000 --> 00:13:01,000\n","只是說可能各方面尚未具備\n","\n","273\n","00:13:01,000 --> 00:13:03,000\n","還沒有完全訓練的好\n","\n","274\n","00:13:03,000 --> 00:13:05,000\n","在這以後是最好的\n","\n","275\n","00:13:05,000 --> 00:13:10,000\n","這以後年紀大了難免有一些要打個折扣等等\n","\n","276\n","00:13:10,000 --> 00:13:13,000\n","就這裡面我們看到\n","\n","277\n","00:13:13,000 --> 00:13:15,000\n","我們的電機系的畢業的同學\n","\n","278\n","00:13:15,000 --> 00:13:18,000\n","過去有幾千人畢業我都看到\n","\n","279\n","00:13:18,000 --> 00:13:22,000\n","我覺得有的人的發展是像這樣\n","\n","280\n","00:13:22,000 --> 00:13:24,000\n","有一定的斜率\n","\n","281\n","00:13:24,000 --> 00:13:28,000\n","但到某一個階段它會慢慢saturate\n","\n","282\n","00:13:28,000 --> 00:13:31,000\n","有的人也許開始向上比較晚\n","\n","283\n","00:13:31,000 --> 00:13:33,000\n","但它斜率比較高\n","\n","284\n","00:13:33,000 --> 00:13:38,000\n","它最後會saturate在比較高的地方\n","\n","285\n","00:13:38,000 --> 00:13:41,000\n","也有的人也許開始的比較快\n","\n","286\n","00:13:41,000 --> 00:13:44,000\n","但是後來會overshoot之後\n","\n","287\n","00:13:44,000 --> 00:13:46,000\n","會開始收斂在比較低的地方等等\n","\n","288\n","00:13:46,000 --> 00:13:48,000\n","每一個人都不一樣\n","\n","289\n","00:13:48,000 --> 00:13:50,000\n","但是當然也有一種人\n","\n","290\n","00:13:50,000 --> 00:13:54,000\n","你會看到他一直向上走\n","\n","291\n","00:13:54,000 --> 00:13:58,000\n","完全沒有saturate\n","\n","292\n","00:13:58,000 --> 00:14:01,000\n","這些人這些差別在哪裡\n","\n","293\n","00:14:01,000 --> 00:14:04,000\n","這些東西差別在哪裡\n","\n","294\n","00:14:04,000 --> 00:14:06,000\n","我以前已經說過這件事\n","\n","295\n","00:14:06,000 --> 00:14:08,000\n","我不要多重複\n","\n","296\n","00:14:08,000 --> 00:14:11,000\n","我說最主要因素有四個\n","\n","297\n","00:14:11,000 --> 00:14:18,000\n","實力、努力、大智\n","\n","298\n","00:14:18,000 --> 00:14:23,000\n","跟self skill這四件事情\n","\n","299\n","00:14:23,000 --> 00:14:29,000\n","我認為真正影響這個的\n","\n","300\n","00:14:29,000 --> 00:14:32,000\n","不是因為電子學考得好不好\n","\n","301\n","00:14:32,000 --> 00:14:35,000\n","不是因為信號與系統念得好不好\n","\n","302\n","00:14:35,000 --> 00:14:37,000\n","也就是我剛才講\n","\n","303\n","00:14:37,000 --> 00:14:39,000\n","你把每一門必修課\n","\n","304\n","00:14:39,000 --> 00:14:41,000\n","當成是單一跑道\n","\n","305\n","00:14:41,000 --> 00:14:43,000\n","跑到第一名並不表示怎樣\n","\n","306\n","00:14:43,000 --> 00:14:45,000\n","我們最後不看那個的\n","\n","307\n","00:14:45,000 --> 00:14:47,000\n","最後看的是這個\n","\n","308\n","00:14:47,000 --> 00:14:49,000\n","這個是怎麼樣影響\n","\n","309\n","00:14:49,000 --> 00:14:51,000\n","我認為是這四件事\n","\n","310\n","00:14:51,000 --> 00:14:55,000\n","就是實力、努力、大智跟self skills\n","\n","311\n","00:14:55,000 --> 00:14:57,000\n","這四件事裡面\n","\n","312\n","00:14:57,000 --> 00:14:59,000\n","我們現在可以summarize\n","\n","313\n","00:14:59,000 --> 00:15:00,000\n","我剛才講的\n","\n","314\n","00:15:00,000 --> 00:15:02,000\n","什麼是實力\n","\n","315\n","00:15:02,000 --> 00:15:05,000\n","實力就是所有的這些\n","\n","316\n","00:15:05,000 --> 00:15:07,000\n","我們電機工程的專業領域裡面\n","\n","317\n","00:15:07,000 --> 00:15:09,000\n","各種東西的實力\n","\n","318\n","00:15:09,000 --> 00:15:11,000\n","實力怎麼厲害法\n","\n","319\n","00:15:11,000 --> 00:15:13,000\n","就是我剛才講的\n","\n","320\n","00:15:13,000 --> 00:15:16,000\n","你如果都是在做全面的學習的話\n","\n","321\n","00:15:16,000 --> 00:15:18,000\n","你就會學到各種該學到的\n","\n","322\n","00:15:18,000 --> 00:15:20,000\n","最後你的實力就是很強的\n","\n","323\n","00:15:20,000 --> 00:15:25,000\n","所以實力最主要就是不要overfitting\n","\n","324\n","00:15:25,000 --> 00:15:27,000\n","要盡量都做\n","\n","325\n","00:15:27,000 --> 00:15:31,000\n","學到該學的全面的學習\n","\n","326\n","00:15:31,000 --> 00:15:33,000\n","努力是沒有疑問\n","\n","327\n","00:15:33,000 --> 00:15:34,000\n","每一個人都了解\n","\n","328\n","00:15:34,000 --> 00:15:36,000\n","確實我們可以看到\n","\n","329\n","00:15:36,000 --> 00:15:38,000\n","一個人在未來的幾十年裡面\n","\n","330\n","00:15:38,000 --> 00:15:40,000\n","有的人他一直努力\n","\n","331\n","00:15:40,000 --> 00:15:42,000\n","有的人慢慢不太努力等等\n","\n","332\n","00:15:42,000 --> 00:15:44,000\n","這個是有明顯差別的\n","\n","333\n","00:15:44,000 --> 00:15:46,000\n","那self skills我剛才已經講了\n","\n","334\n","00:15:46,000 --> 00:15:50,000\n","就是很多我們平常沒有算成績\n","\n","335\n","00:15:50,000 --> 00:15:52,000\n","覺得大家不重視的事情\n","\n","336\n","00:15:52,000 --> 00:15:54,000\n","其實它常常是很重要的\n","\n","337\n","00:15:54,000 --> 00:15:56,000\n","你如果好好的\n","\n","338\n","00:15:56,000 --> 00:16:00,000\n","多在各種課業外的事情上\n","\n","339\n","00:16:00,000 --> 00:16:02,000\n","增長進步的話\n","\n","340\n","00:16:02,000 --> 00:16:04,000\n","你這些東西會很強\n","\n","341\n","00:16:04,000 --> 00:16:06,000\n","你會很厲害的\n","\n","342\n","00:16:06,000 --> 00:16:08,000\n","當然對少數人而言\n","\n","343\n","00:16:08,000 --> 00:16:09,000\n","他天生就有\n","\n","344\n","00:16:09,000 --> 00:16:10,000\n","他可能不需要\n","\n","345\n","00:16:10,000 --> 00:16:12,000\n","這是每一個人不一樣的\n","\n","346\n","00:16:12,000 --> 00:16:14,000\n","那這三個我都提過了\n","\n","347\n","00:16:14,000 --> 00:16:16,000\n","那麼大致我還沒有提\n","\n","348\n","00:16:16,000 --> 00:16:18,000\n","其實大致沒有什麼要特別說的\n","\n","349\n","00:16:18,000 --> 00:16:21,000\n","那應該就是我剛才前面有講過\n","\n","350\n","00:16:21,000 --> 00:16:26,000\n","就是每一個人可以有你自己的長程目標\n","\n","351\n","00:16:26,000 --> 00:16:29,000\n","那有的人本來就有了\n","\n","352\n","00:16:29,000 --> 00:16:32,000\n","有的人也許我平常沒有想過\n","\n","353\n","00:16:32,000 --> 00:16:37,000\n","那你可以在適當時機開始想\n","\n","354\n","00:16:37,000 --> 00:16:40,000\n","我有沒有想要做什麼事情\n","\n","355\n","00:16:40,000 --> 00:16:43,000\n","哪些事情可能是我的長程目標\n","\n","356\n","00:16:43,000 --> 00:16:48,000\n","我希望最後讓我花個5年10年\n","\n","357\n","00:16:48,000 --> 00:16:50,000\n","15年或者更長\n","\n","358\n","00:16:50,000 --> 00:16:52,000\n","我把我的很多的努力\n","\n","359\n","00:16:52,000 --> 00:16:55,000\n","都來把某一些事情做得非常漂亮\n","\n","360\n","00:16:55,000 --> 00:16:57,000\n","那是我很想做的事\n","\n","361\n","00:16:57,000 --> 00:17:00,000\n","那就是長程目標\n","\n","362\n","00:17:00,000 --> 00:17:04,000\n","如果我覺得做那些事情會讓我非常的\n","\n","363\n","00:17:04,000 --> 00:17:05,000\n","覺得有意義\n","\n","364\n","00:17:05,000 --> 00:17:07,000\n","願意花功夫下去做的\n","\n","365\n","00:17:07,000 --> 00:17:09,000\n","那就是我的長程目標\n","\n","366\n","00:17:09,000 --> 00:17:12,000\n","那有的人如果可以想出這個來的話\n","\n","367\n","00:17:12,000 --> 00:17:15,000\n","那就是他的大致\n","\n","368\n","00:17:15,000 --> 00:17:17,000\n","那越是有這種大致的人\n","\n","369\n","00:17:17,000 --> 00:17:20,000\n","也比較容易向上衝\n","\n","370\n","00:17:20,000 --> 00:17:25,000\n","那我感覺起來真正影響的就是這四件事\n","\n","\n"]}],"source":["''' Open the SRT file and read its content.\n","The format of SRT is:\n","\n","[Index]\n","[Begin time] (hour:minute:second) --> [End time] (hour:minute:second)\n","[Transcription]\n","\n","'''\n","\n","with open(output_subtitle_path, 'r', encoding='utf-8') as file:\n","    content = file.read()\n","\n","print(content)"]},{"cell_type":"markdown","metadata":{"id":"E7JcN-kUDE_g"},"source":["# Part3 - Preprocess the results of automatic speech recognition"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1720230826279,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"P2R40faVDShf"},"outputs":[],"source":["def extract_and_save_text(srt_filename, output_filename):\n","\n","    '''\n","    (1) Objective:\n","        - This function extracts the text from an SRT file and saves it to a new text file.\n","        - It also converts the Simplified Chinese to Traditional Chinese.\n","\n","    (2) Arguments:\n","\n","        - srt_filename: The path to the SRT file.\n","\n","        - output_filename: The name of the output text file.\n","\n","    (3) Example:\n","        - If your SRT file is named 'subtitle.srt' and you want to save the extracted text to a file named 'output.txt', you can use the function like this:\n","            extract_and_save_text('subtitle.srt', 'output.txt')\n","\n","    '''\n","\n","    # Open the SRT file and read its content.\n","    with open(srt_filename, 'r', encoding='utf-8') as file:\n","        content = file.read()\n","\n","    # Use regular expression to remove the timecode.\n","    pure_text = re.sub(r'\\d+\\n\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}\\n', '', content)\n","\n","    # Remove the empty lines.\n","    pure_text = re.sub(r'\\n\\n+', '\\n', pure_text)\n","\n","    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n","    cc = OpenCC('s2t')\n","    pure_text_conversion = cc.convert(pure_text)\n","\n","    # Write the extracted text to a new file.\n","    with open(output_filename, 'w', encoding='utf-8') as output_file:\n","        output_file.write(pure_text_conversion)\n","\n","    print(f'Extracted text has been saved to {output_filename}.\\n\\n')\n","\n","    return pure_text_conversion"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1720230826279,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"tWDl1vuADd0e"},"outputs":[],"source":["def chunk_text(text, max_length):\n","    \"\"\"\n","    (1) Objective:\n","        - This function is used to split a long string into smaller strings of a specified length.\n","\n","    (2) Arguments:\n","        - text: str, the long string to be split.\n","        - max_length: int, the maximum length of each smaller string.\n","\n","    (3) Returns:\n","        - split_text: list, a list of smaller strings.\n","\n","    (3) Example:\n","        - If you want to split a string named \"long_string\" into smaller strings of length 100, you can use the function like this:\n","            chunk_text(long_string, 100)\n","\n","    \"\"\"\n","\n","    return textwrap.wrap(text, max_length)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1720230826279,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"aO01S41pOsSP"},"outputs":[],"source":["''' In this block, you can modify your desired parameters and the path of input file. '''\n","\n","# # The length of the text chunks.\n","chunk_length = 512"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1720230826280,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"O-PpbkoS-5bI","outputId":"eec9ea3a-d432-4489-ea62-241bdabd825b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Extracted text has been saved to ./output-信號與人生.txt.\n","\n","\n","Review the results of splitting the long text into several short texts.\n","\n","\n","========== The 1-st segment of the split (505 words) ==========\n","\n","\n","每次說這個學問是做出來的 什麼意思? 要做才會獲得學問 你如果每天光是坐在那裡聽 學問很可能是左耳進右耳出的 你光是坐在那兒讀\n","\n","學問可能從眼睛進入腦海之後就忘掉了 如何能夠學問在腦海裡面 真的變成你自己學問 就是要做 可能有很多同學有這個經驗 你如果去修某一門課 或者做某一個實驗\n","\n","在期末就是要教一個final project 那個final project就是要你把 學到的很多東西 最後整合在你的final project裡面\n","\n","最後做出來的時候 就是把它們都整合了 當你學期結束 真的把final project做完的時候 你會忽然發現 我真的學到很多東西 那就是做出來的學問\n","\n","也許可以舉另外一個例子 就是你如果學了某一些很複雜的演算法 或者什麼 好像覺得那些不見得在你的腦海裡 可是後來老師出了個習題 那個習題教你寫一個很大的程式\n","\n","要把所有東西都包進去 當你把這個程式寫完的時候你會發現 你忽然把演算法裡所有東西都弄通了 那就是學問是做出來的 所以我們永遠要記得 盡量多動手多做\n","\n","在動手跟做的過程之中 學問纔可以變成是自己的 同樣的情形就是說 很多時候這樣動手或者做的表現或者成績 沒有一個成績單上的數字\n","\n","\n","========== The 2-nd segment of the split (506 words) ==========\n","\n","\n","使得很多人覺得那不重要 很多人甚至覺得這門課要做final project 我就不修了太累了 或者說那門課需要怎麼樣怎麼樣太累 我就不要做了\n","\n","而不知道其實那個纔是讓你做的機會 然後可以學到最多 也就是說雖然很可能那麼辛苦的做很多事 沒有讓你獲得什麼具體成績 對你的overfitting可能沒有幫助\n","\n","可是對你的全面學習是很有幫助 是該學的 那不要漏掉這些事 那這是我所說的 那這個課業內可以做的這些事 那剛才我們講到思考的時候 我覺得我漏掉一點\n","\n","你如果修我的信號課你可能會發現 我上課沒講到一個數學式子的時候 我通常都不推他的 我是在解釋那個數學式子在說什麼話 同樣的呢 沒講到一個什麼什麼事情的時候\n","\n","我通常就在解釋他在說什麼話 也就是說 我在講的就是我讀到特本那裡的時候 我心裡怎麼想的 也就是我在告訴同學如何這個讀書的時候 如何一面讀一面練習思考\n","\n","那這個纔是最重要的一件事 如何培養自己思考的能力 跟培養思考的習慣 我覺得最好的辦法就是讀書的時候 凡是讀到一個數學式子都去想一想 那個數學式子到底在說什麼\n","\n","凡是讀到特本上講什麼就去想一想 那個到底在說什麼 你要真的瞭解他在說什麼的時候 你就用了很多思考的功夫\n","\n","\n","========== The 3-rd segment of the split (504 words) ==========\n","\n","\n","你就在練習自己思考的能力了 好 以上說的是課業內的部分 那當然除了課業內之外呢 還有一大堆是不在課業內的 那就是課業外的 課業外也有很多式的 那我們可以舉例來說\n","\n","課業外有什麼可以學習的 那我通常把學習定義成為 什麼是學習 學習就是一種增長 一種進步 然後獲得快樂 這就是學習 所以即使是課業外的任何事情\n","\n","只要你覺得是有增長的 是有進步的 讓你覺得快樂的 那應該就是值得學習的地方 那我們可以舉很多例子 譬如說很多同學喜歡打球 打球是不是學習 當然是\n","\n","在打球中間有沒有增長 當然是 在打球中間有沒有增長 當然有增長 打球不只是對健康有增長 而且可能對於譬如說手腦協調 譬如說團隊精神 譬如說個人之間的互動\n","\n","什麼可能都有幫助 所以打球當然是有增長的 那當然是很好的學習的機會 有人喜歡爬山 爬山是不是好的學習機會 當然是 這個我以前兩年前就講過很多 爬山可以學到很多的\n","\n","那爬山當然是一種學習 有人說我不喜歡爬山 我去旅行好不好 旅行當然好 旅行可以增長見識 可以擴增事業 可以增加很多很多 當然是有進步的 所以當然是很好的學習\n","\n","你凡是獲得快樂都是很好的事 那這些都值得下功夫去 把它看成是學習 都值得下功夫去做的\n","\n","\n","========== The 4-th segment of the split (506 words) ==========\n","\n","\n","我們再講另外一系列 譬如說 有人說談戀愛是不是學習 談戀愛除了你在談戀愛上 會有收穫以外 本身也是有收穫的 因為讓你體驗到人跟人之間 的各種感覺\n","\n","人跟人之間的各種期待等等 有沒有幫助 當然有幫助 對每一個人都是很好的學習 所以談戀愛當然是一件很好的事 有人會說那要靠緣分 沒有緣分沒有辦法 對不對 對\n","\n","但是你不是一定要談戀愛嗎 你可以交朋友 交朋友是不是學習 當然是 交朋友也一樣 讓我們學到很多人際的互動 學到很多人跟人之間的溝通 人跟人之間的期待\n","\n","人跟人之間的感覺 這都是交朋友之後學到的 對我們電機系的同學而言 你四周有一大羣好同學 都是很好的交朋友的對象 你下一番功夫交朋友好不好 好 當然是有幫助的\n","\n","另外當然我們可以舉很多 我們最現成的例子 譬如說我們的戲學會辦各種活動 那些活動有沒有幫助 當然有 我們舉例來講電業 你如果去參加某一個舞跳個舞\n","\n","或者參加某個劇演個劇 有沒有幫助 當然有幫助 你在這中間一定發現有所增長 有所進步 那是為什麼有那麼多同學要去參加 就是因為發現那個確實是有增長有進步 有的人說\n","\n","我不去跳那個舞 或者演那個劇 我做幕後的 譬如說是幕後的什麼規劃 或者說是什麼光舞的什麼軟體組\n","\n","\n","========== The 5-th segment of the split (501 words) ==========\n","\n","\n","還是什麼服裝道具組 一樣 那個都是可以有獲得很多的增長 很多進步的 當然都是很有用的 都是很好的學習 那當然也包括電業以外的戲學會 其他的各種活動都一樣\n","\n","也包括電機系以外的其他的校內 或者校外的各種活動幾乎都一樣 都可以讓人有所增長有所進步 都是很好的學習的機會 都是很好的學習 同樣的問題是這些東西都沒有考試\n","\n","沒有成績 不能顯示在成績單上 因此對有一些同學會認為那個浪費時間 我不需要花時間去做那個 因為不影響我的overfitting的目標 裡面沒有這個嘛\n","\n","具體成績沒有這些嘛 那不要這樣想 因為那些都非常的重要 都對你發展非常的重要 那我們說電機工程 今天的電機工程 很少什麼事情自己一個人可以做成功的\n","\n","你必須跟很多人一起 纔可能做成功一個非常重要的 有意義的工作 那當你跟一羣人在一起做的時候 你必須學會如何進入一個團隊 從邊緣開始慢慢進入核心\n","\n","從底層開始慢慢變成leader 然後如何可以推動你想做的事 如何變成可以做到你想做的事等等 這些都是很重要的 那我們通常稱這些東西 是所謂的soft\n","\n","skills 也就是軟實力 所謂軟實力就是硬實力以外的軟實力 硬實力是說你電子學的功力 數學的功力\n","\n","\n","========== The 6-th segment of the split (504 words) ==========\n","\n","\n","這個城市能力這種是硬實力 軟實力我們主要就是講各種人際之間的 在人跟人之間的各種能力 包括溝通能力協調能力交朋友的能力 說服人的能力團隊精神領導能力等等\n","\n","那些就是所謂的soft skills 重要不重要重要 你看到任何一個成功的電機工程師 他都有一堆這種 這個纔是他成功的一個非常重要的關鍵 這種東西怎麼來\n","\n","我們剛才講的各種課業外的 各種學習增長的機會 都可以幫助一個人塑造他的soft skills 是有少數人的這些soft skills是天生的 他天生就厲害\n","\n","有沒有 有 但這種人畢竟沒那麼多 對很多人而言 他的soft skills是自己努力慢慢培養起來的 我剛才一開始前面講的那一段 我說我在進臺大電機系以前\n","\n","我幾乎不會交朋友 我不太會說話 我在讀大學的四年裡面改變我自己 讓我變成有很多這方面的能力的人 其實最重要就是我的很多soft skills 都是我自己培養\n","\n","在讀臺大電機系的四年裡面 獲得的非常多這方面的收穫的 那是為什麼我每次都要強調 這個東西有多麼重要 我之前曾經在幾年前的這個 信號與人生裡面有說到這一件事\n","\n","我現在不要重複 但是我簡單的summarize 我說我們電機系的電機工程師的\n","\n","\n","========== The 7-th segment of the split (502 words) ==========\n","\n","\n","一生career的發展 黃金實在是在什麼時候 我認為是在35歲到55歲 這20年是我們的黃金時代 在這以前當然更好 只是說可能各方面尚未具備 還沒有完全訓練的好\n","\n","在這以後是最好的 這以後年紀大了難免有一些要打個折扣等等 就這裡面我們看到 我們的電機系的畢業的同學 過去有幾千人畢業我都看到 我覺得有的人的發展是像這樣\n","\n","有一定的斜率 但到某一個階段它會慢慢saturate 有的人也許開始向上比較晚 但它斜率比較高 它最後會saturate在比較高的地方 也有的人也許開始的比較快\n","\n","但是後來會overshoot之後 會開始收斂在比較低的地方等等 每一個人都不一樣 但是當然也有一種人 你會看到他一直向上走 完全沒有saturate\n","\n","這些人這些差別在哪裡 這些東西差別在哪裡 我以前已經說過這件事 我不要多重複 我說最主要因素有四個 實力、努力、大智 跟self skill這四件事情\n","\n","我認為真正影響這個的 不是因為電子學考得好不好 不是因為信號與系統念得好不好 也就是我剛才講 你把每一門必修課 當成是單一跑道 跑到第一名並不表示怎樣\n","\n","我們最後不看那個的 最後看的是這個 這個是怎麼樣影響 我認為是這四件事\n","\n","\n","========== The 8-th segment of the split (512 words) ==========\n","\n","\n","就是實力、努力、大智跟self skills 這四件事裡面 我們現在可以summarize 我剛才講的 什麼是實力 實力就是所有的這些\n","\n","我們電機工程的專業領域裡面 各種東西的實力 實力怎麼厲害法 就是我剛才講的 你如果都是在做全面的學習的話 你就會學到各種該學到的 最後你的實力就是很強的\n","\n","所以實力最主要就是不要overfitting 要盡量都做 學到該學的全面的學習 努力是沒有疑問 每一個人都瞭解 確實我們可以看到 一個人在未來的幾十年裡面\n","\n","有的人他一直努力 有的人慢慢不太努力等等 這個是有明顯差別的 那self skills我剛才已經講了 就是很多我們平常沒有算成績 覺得大家不重視的事情\n","\n","其實它常常是很重要的 你如果好好的 多在各種課業外的事情上 增長進步的話 你這些東西會很強 你會很厲害的 當然對少數人而言 他天生就有 他可能不需要\n","\n","這是每一個人不一樣的 那這三個我都提過了 那麼大致我還沒有提 其實大致沒有什麼要特別說的 那應該就是我剛才前面有講過 就是每一個人可以有你自己的長程目標\n","\n","那有的人本來就有了 有的人也許我平常沒有想過 那你可以在適當時機開始想 我有沒有想要做什麼事情 哪些事情可能是我的長程目標\n","\n","\n","========== The 9-th segment of the split (169 words) ==========\n","\n","\n","我希望最後讓我花個5年10年 15年或者更長 我把我的很多的努力 都來把某一些事情做得非常漂亮 那是我很想做的事 那就是長程目標\n","\n","如果我覺得做那些事情會讓我非常的 覺得有意義 願意花功夫下去做的 那就是我的長程目標 那有的人如果可以想出這個來的話 那就是他的大致 那越是有這種大致的人\n","\n","也比較容易向上衝 那我感覺起來真正影響的就是這四件事\n","\n"]}],"source":["# Extracts the text from an SRT file and saves it to a new text file\n","pure_text = extract_and_save_text(srt_filename=output_subtitle_path, output_filename=output_raw_text_path)\n","\n","# Split a long document into smaller chunks of a specified length\n","chunks = chunk_text(text=pure_text, max_length=512)\n","\n","# You can see the number of words and contents in each paragraph.\n","print(\"Review the results of splitting the long text into several short texts.\\n\")\n","for index, chunk in enumerate(chunks):\n","    if index == 0:\n","        print(f\"\\n========== The {index + 1}-st segment of the split ({len(chunk)} words) ==========\\n\\n\")\n","        for text in textwrap.wrap(chunk, 80):\n","            print(f\"{text}\\n\")\n","    elif index == 1:\n","        print(f\"\\n========== The {index + 1}-nd segment of the split ({len(chunk)} words) ==========\\n\\n\")\n","        for text in textwrap.wrap(chunk, 80):\n","            print(f\"{text}\\n\")\n","    elif index == 2:\n","        print(f\"\\n========== The {index + 1}-rd segment of the split ({len(chunk)} words) ==========\\n\\n\")\n","        for text in textwrap.wrap(chunk, 80):\n","            print(f\"{text}\\n\")\n","    else:\n","        print(f\"\\n========== The {index + 1}-th segment of the split ({len(chunk)} words) ==========\\n\\n\")\n","        for text in textwrap.wrap(chunk, 80):\n","            print(f\"{text}\\n\")"]},{"cell_type":"markdown","metadata":{"id":"Wuvx30fkW4kU"},"source":["# Part4 - Summarization\n"]},{"cell_type":"markdown","metadata":{"id":"7mr9Kz634zT2"},"source":["## **You only need to choose one of the following parts.**"]},{"cell_type":"markdown","metadata":{"id":"XCM4kPuBXh7R"},"source":["## **If you want to use Gemini, begin with this part.**\n","##### (1) You can refer to https://shorturl.at/X0NDY (Page 35) for obtaining Gemini API key.\n","##### (2) You can refer to https://ai.google.dev/models/gemini for more details about which models you can use."]},{"cell_type":"code","execution_count":67,"metadata":{"executionInfo":{"elapsed":280,"status":"ok","timestamp":1720232219586,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"anuFrhHNkMgY"},"outputs":[],"source":["def summarization(summarization_prompt, model_name=\"gemini-pro\", temperature=0.0, top_p=1.0, max_tokens=512):\n","    \"\"\"\n","    (1) Objective:\n","        - Use the OpenAI Chat API to summarize a given text.\n","\n","    (2) Arguments:\n","        - summarization_prompt: The summarization prompt.\n","        - model_name: The model name, default is \"gemini-pro\". You can refer to \"https://ai.google.dev/models/gemini\" for more details.\n","        - temperature: Controls randomness in the response. Lower values make responses more deterministic, default is 0.0.\n","        - top_p: Controls diversity via nucleus sampling. Higher values lead to more diverse responses, default is 1.0.\n","        - max_tokens: The maximum number of tokens to generate in the completion, default is 512.\n","\n","    (3) Return:\n","        - The summarized text.\n","\n","    (4) Example:\n","        - If the text is \"ABC\" and the summarization prompt is \"DEF\", model_name is \"gemini-pro\",\n","          temperature is 0.0, top_p is 1.0, and max_tokens is 512, then you can call the function like this:\n","\n","              summarization(text=\"ABC\", summarization_prompt=\"DEF\", model_name=\"gemini-pro\", temperature=0.0, top_p=1.0, max_tokens=512)\n","\n","    \"\"\"\n","\n","    # The user prompt is a concatenation of the summarization_prompt and text.\n","    user_prompt = summarization_prompt\n","\n","    # Load the generative model.\n","    model = genai.GenerativeModel(model_name)\n","\n","    # Set the generation configuration.\n","    generation_config = genai.GenerationConfig(temperature=temperature, top_p=top_p, max_output_tokens=max_tokens)\n","\n","    while True:\n","\n","        try:\n","            # Use the OpenAI Chat API to summarize the text.\n","            response = model.generate_content(contents=user_prompt, generation_config=generation_config)\n","\n","            break\n","\n","        except:\n","            # If the API call fails, wait for 1 second and try again.\n","            print(\"The API call fails, wait for 1 second and try again.\")\n","            time.sleep(1)\n","\n","    return response.text"]},{"cell_type":"code","execution_count":70,"metadata":{"cellView":"form","executionInfo":{"elapsed":219,"status":"ok","timestamp":1720232225765,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"plyvWCvXllz3"},"outputs":[],"source":["# @title Parameter Setting of Gemini { run: \"auto\" }\n","''' In this block, you can modify your desired parameters and set your api key. '''\n","\n","# Your google api key.\n","# @markdown **google_api_key**: Your google api key.\n","google_api_key = \"AIzaSyBVjAGJ9KbB4rO4pYAYwr5T3vbiNi7YtFg\" # @param {type:\"string\"}\n","\n","# The model name. You can refer to \"https://ai.google.dev/models/gemini\" for more details.\n","# @markdown **model_name**: The model name. You can refer to \"https://ai.google.dev/models/gemini\" for more details.\n","model_name = \"gemini-pro\" # @param {type:\"string\"}\n","\n","# Controls randomness in the response. Lower values make responses more deterministic\n","# @markdown **temperature**: Controls randomness in the response. Lower values make responses more deterministic.\n","temperature = 0.2 # @param {type:\"slider\", min:0, max:1, step:0.1}\n","\n","# Controls diversity via nucleus sampling. Higher values lead to more diverse responses\n","# @markdown **top_p**: Controls diversity via nucleus sampling. Higher values lead to more diverse responses.\n","top_p = 1.0 # @param {type:\"slider\", min:0, max:1, step:0.1}"]},{"cell_type":"code","execution_count":71,"metadata":{"executionInfo":{"elapsed":285,"status":"ok","timestamp":1720232228500,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"Eed0NjqJtGfM"},"outputs":[],"source":["# Set Google API key.\n","genai.configure(api_key=google_api_key)"]},{"cell_type":"markdown","metadata":{"id":"csw7hxrHsJym"},"source":["### We offer the following two methods for summarization.\n","Reference: https://reurl.cc/VzagLA"]},{"cell_type":"markdown","metadata":{"id":"YGHFGCyasp9h"},"source":["#### **If you want to use the method of Multi-Stage Summarization, begin with this part.**\n"]},{"cell_type":"code","execution_count":72,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1720232230598,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"_TsX6dBgs1iw"},"outputs":[],"source":["# @title Prompt Setting of Gemini Multi-Stage Summarization: Paragraph { run: \"auto\" }\n","''' You can modify the summarization prompt and maximum number of tokens. '''\n","''' However, DO NOT modify the part of <text>.'''\n","\n","# The maximum number of tokens to generate in the completion.\n","# @markdown **max_tokens**: The maximum number of tokens to generate in the completion.\n","max_tokens = 350 # @param {type:\"integer\"}\n","\n","# @markdown #### Changing **summarization_prompt_template**\n","# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n","summarization_prompt_template = \"用 300 個字內寫出這段文字的摘要，其中包括要點和所有重要細節：<text>\" # @param {type:\"string\"}"]},{"cell_type":"markdown","metadata":{"id":"PkQdOOixuJU9"},"source":["##### Step1: Split the long text into multiple smaller pieces and obtain summaries for each smaller text piece separately\n"]},{"cell_type":"markdown","metadata":{"id":"olrUkpe615-E"},"source":["The code block below takes about **40** seconds to run when using the (1) **gemini-pro** model, (2) length of chunks is 512 and (3) maximum number of tokens is 350, but the actual time may vary depending on the condition of Colab and the status of the Google API."]},{"cell_type":"code","execution_count":75,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":44741,"status":"ok","timestamp":1720232317941,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"5KOp_d6XloCn","outputId":"2ff08b47-fe15-4e9e-fb5f-5df5c1d7da98"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------Summary of Segment 1----------------------------\n","\n","「做出來的學問」強調學習需要實踐。單純聽講或閱讀可能無法讓知識內化。通過動手做，例如完成專題或編寫程式，學生可以將所學知識整合並真正理解。這種實踐過程使知識成為\n","\n","自己的，即使沒有傳統的成績評分。因此，學生應積極參與實作活動，以最大限度地吸收和保留學到的內容。\n","\n","Length of summary for segment 1: 128\n","Time taken to generate summary for segment 1: 4.41 sec.\n","\n","----------------------------Summary of Segment 2----------------------------\n","\n","許多學生認為困難的課程或作業不重要，甚至因此放棄修課。然而，這些挑戰正是學習的機會，能培養全面的理解力。\n","\n","作者建議學生在學習時，不要只關注具體成績，而應專注於理解概念和培養思考能力。通過思考數學公式和文本內容的含義，學生可以培養思考習慣和理解力。\n","\n","作者強調，讀書時思考是至關重要的，因為它能幫助學生深入理解材料，並培養批判性思維能力。通過持續練習思考，學生可以提高他們的全面學習能力。\n","\n","Length of summary for segment 2: 194\n","Time taken to generate summary for segment 2: 5.54 sec.\n","\n","----------------------------Summary of Segment 3----------------------------\n","\n","學習不僅限於課業，課外活動也提供了增長、進步和快樂的機會。打球可以培養手腦協調、團隊精神和人際互動。爬山可以增長見識，擴展視野。旅行可以增長見識，擴展事業。任何\n","\n","能帶來快樂的活動都可以被視為學習，值得投入時間和精力。\n","\n","Length of summary for segment 3: 107\n","Time taken to generate summary for segment 3: 4.53 sec.\n","\n","----------------------------Summary of Segment 5----------------------------\n","\n","參與課外活動和校內外活動可以帶來許多成長和進步，包括電機工程以外的領域。這些活動提供了寶貴的學習機會，培養團隊合作、領導力和溝通等軟實力。儘管這些活動沒有考試或\n","\n","成績，但它們對於個人和職業發展至關重要。在電機工程領域，團隊合作和軟實力對於成功至關重要，因為很少有事情可以單獨完成。因此，參與課外活動和校內外活動對於培養這些\n","\n","技能並為未來的成功做好準備非常重要。\n","\n","Length of summary for segment 5: 178\n","Time taken to generate summary for segment 5: 4.68 sec.\n","\n","----------------------------Summary of Segment 6----------------------------\n","\n","軟實力是指人際交往能力，包括溝通、協調、交友、說服、團隊精神和領導力等。這些能力對成功至關重要，即使是電機工程師也需要具備。\n","\n","軟實力通常不是天生的，而是通過課外活動和學習機會培養的。作者在台大電機系就讀期間，通過努力培養了這些能力，並強調了它們的重要性。\n","\n","作者認為，軟實力是電機工程師成功的關鍵，並建議學生重視課外活動和學習機會，以培養這些能力。\n","\n","Length of summary for segment 6: 175\n","Time taken to generate summary for segment 6: 5.33 sec.\n","\n","----------------------------Summary of Segment 7----------------------------\n","\n","職業生涯的黃金時期通常在 35 至 55 歲之間。在此期間，個人通常具備了必要的技能和經驗，並處於事業的巔峰。\n","\n","電機系畢業生的職業發展軌跡各不相同。有些人從一開始就表現出色，而另一些人則在後來的職業生涯中取得成功。  影響職業發展的關鍵因素包括：  *\n","\n","實力：技術能力和知識 * 努力：勤奮和奉獻精神 * 大智：智慧和決策能力 * 自我技能：人際交往能力和自我管理能力\n","\n","職業發展並非線性，而是可能出現飽和、過度調整或持續增長等模式。\n","\n","Length of summary for segment 7: 218\n","Time taken to generate summary for segment 7: 5.26 sec.\n","\n","----------------------------Summary of Segment 8----------------------------\n","\n","實力來自於全面的學習，涵蓋電機工程領域的各項知識。努力是不可或缺的，持續的努力將帶來顯著的差異。自我技能包括課外活動和個人成長，這些技能往往被低估，但卻至關重要\n","\n","。  除了這三項要素外，個人應設定長期的目標，作為努力的方向。目標可以激勵個人持續進步，並為其職業生涯提供明確的指引。\n","\n","Length of summary for segment 8: 139\n","Time taken to generate summary for segment 8: 5.13 sec.\n","\n","----------------------------Summary of Segment 9----------------------------\n","\n","長程目標是個人願意投入大量時間和精力去實現的目標，這些目標通常具有深遠的意義。設定長程目標可以激勵個人向上奮鬥，並提供人生方向。\n","\n","要設定有效的長程目標，個人需要考慮以下四個因素：  * **意義感：**目標應與個人的價值觀和熱情相符，激勵他們投入時間和精力。 *\n","\n","**可行性：**目標應具有挑戰性，但又不能過於遙不可及，以保持個人動力。 * **時間框架：**長程目標通常需要數年甚至數十年才能實現，個人應設定現實的時間表。\n","\n","* **具體性：**目標應明確具體，以便個人可以制定行動計畫並追蹤進度。\n","\n","Length of summary for segment 9: 250\n","Time taken to generate summary for segment 9: 5.41 sec.\n","\n"]}],"source":["paragraph_summarizations = []\n","\n","# First, we summarize each section that has been split up separately.\n","for index, chunk in enumerate(chunks):\n","  try:\n","    # Record the start time.\n","    start = time.time()\n","\n","    # Construct summarization prompt.\n","    summarization_prompt = summarization_prompt_template.replace(\"<text>\", chunk)\n","\n","    # We summarize each section that has been split up separately.\n","    response = summarization(summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n","    # response = summarization(summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p)\n","\n","    # Calculate the execution time and round it to 2 decimal places.\n","    cost_time = round(time.time() - start, 2)\n","\n","    # Print the summary and its length.\n","    print(f\"----------------------------Summary of Segment {index + 1}----------------------------\\n\")\n","    for text in textwrap.wrap(response, 80):\n","        print(f\"{text}\\n\")\n","    print(f\"Length of summary for segment {index + 1}: {len(response)}\")\n","    print(f\"Time taken to generate summary for segment {index + 1}: {cost_time} sec.\\n\")\n","\n","    # Record the result.\n","    paragraph_summarizations.append(response)\n","  except:\n","    continue"]},{"cell_type":"code","execution_count":76,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":206,"status":"ok","timestamp":1720232348737,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"amp-gOibmpvK","outputId":"880c5598-762f-415a-85a0-1cea8d9f908a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Summary of segment 1: 「做出來的學問」強調學習需要實踐。單純聽講或閱讀可能無法讓知識內化。通過動手做，例如完成專題或編寫程式，學生可以將所學知識整合並真正理解。這種實踐過程使知識成為自己的，即使沒有傳統的成績評分。因此，學生應積極參與實作活動，以最大限度地吸收和保留學到的內容。\n","Summary of segment 2: 許多學生認為困難的課程或作業不重要，甚至因此放棄修課。然而，這些挑戰正是學習的機會，能培養全面的理解力。\n","\n","作者建議學生在學習時，不要只關注具體成績，而應專注於理解概念和培養思考能力。通過思考數學公式和文本內容的含義，學生可以培養思考習慣和理解力。\n","\n","作者強調，讀書時思考是至關重要的，因為它能幫助學生深入理解材料，並培養批判性思維能力。通過持續練習思考，學生可以提高他們的全面學習能力。\n","Summary of segment 3: 學習不僅限於課業，課外活動也提供了增長、進步和快樂的機會。打球可以培養手腦協調、團隊精神和人際互動。爬山可以增長見識，擴展視野。旅行可以增長見識，擴展事業。任何能帶來快樂的活動都可以被視為學習，值得投入時間和精力。\n","Summary of segment 4: 參與課外活動和校內外活動可以帶來許多成長和進步，包括電機工程以外的領域。這些活動提供了寶貴的學習機會，培養團隊合作、領導力和溝通等軟實力。儘管這些活動沒有考試或成績，但它們對於個人和職業發展至關重要。在電機工程領域，團隊合作和軟實力對於成功至關重要，因為很少有事情可以單獨完成。因此，參與課外活動和校內外活動對於培養這些技能並為未來的成功做好準備非常重要。\n","Summary of segment 5: 軟實力是指人際交往能力，包括溝通、協調、交友、說服、團隊精神和領導力等。這些能力對成功至關重要，即使是電機工程師也需要具備。\n","\n","軟實力通常不是天生的，而是通過課外活動和學習機會培養的。作者在台大電機系就讀期間，通過努力培養了這些能力，並強調了它們的重要性。\n","\n","作者認為，軟實力是電機工程師成功的關鍵，並建議學生重視課外活動和學習機會，以培養這些能力。\n","Summary of segment 6: 職業生涯的黃金時期通常在 35 至 55 歲之間。在此期間，個人通常具備了必要的技能和經驗，並處於事業的巔峰。\n","\n","電機系畢業生的職業發展軌跡各不相同。有些人從一開始就表現出色，而另一些人則在後來的職業生涯中取得成功。\n","\n","影響職業發展的關鍵因素包括：\n","\n","* 實力：技術能力和知識\n","* 努力：勤奮和奉獻精神\n","* 大智：智慧和決策能力\n","* 自我技能：人際交往能力和自我管理能力\n","\n","職業發展並非線性，而是可能出現飽和、過度調整或持續增長等模式。\n","Summary of segment 7: 實力來自於全面的學習，涵蓋電機工程領域的各項知識。努力是不可或缺的，持續的努力將帶來顯著的差異。自我技能包括課外活動和個人成長，這些技能往往被低估，但卻至關重要。\n","\n","除了這三項要素外，個人應設定長期的目標，作為努力的方向。目標可以激勵個人持續進步，並為其職業生涯提供明確的指引。\n","Summary of segment 8: 長程目標是個人願意投入大量時間和精力去實現的目標，這些目標通常具有深遠的意義。設定長程目標可以激勵個人向上奮鬥，並提供人生方向。\n","\n","要設定有效的長程目標，個人需要考慮以下四個因素：\n","\n","* **意義感：**目標應與個人的價值觀和熱情相符，激勵他們投入時間和精力。\n","* **可行性：**目標應具有挑戰性，但又不能過於遙不可及，以保持個人動力。\n","* **時間框架：**長程目標通常需要數年甚至數十年才能實現，個人應設定現實的時間表。\n","* **具體性：**目標應明確具體，以便個人可以制定行動計畫並追蹤進度。\n","\n"]}],"source":["# First, we collect all the summarizations obtained before and print them.\n","\n","collected_summarization = \"\"\n","for index, paragraph_summarization in enumerate(paragraph_summarizations):\n","    collected_summarization += f\"Summary of segment {index + 1}: {paragraph_summarization}\\n\"\n","\n","print(collected_summarization)"]},{"cell_type":"markdown","metadata":{"id":"y08WjQxiuZ0k"},"source":["#####Step2: After obtaining summaries for each smaller text piece separately, process these summaries to generate the final summary."]},{"cell_type":"code","execution_count":77,"metadata":{"executionInfo":{"elapsed":214,"status":"ok","timestamp":1720232356917,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"V4GEhPEIudBe"},"outputs":[],"source":["# @title Prompt Setting of Gemini Multi-Stage Summarization: Total { run: \"auto\" }\n","''' You can modify the summarization prompt and maximum number of tokens. '''\n","''' However, DO NOT modify the part of <text>.'''\n","\n","# We set the maximum number of tokens to ensure that the final summary does not exceed 550 tokens.\n","# @markdown **max_tokens**: We set the maximum number of tokens to ensure that the final summary does not exceed 550 tokens.\n","max_tokens = 550 # @param {type:\"integer\"}\n","\n","# @markdown ### Changing **summarization_prompt_template**\n","# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n","summarization_prompt_template = \"在 500 字以內寫出以下文字的簡潔摘要：<text>\" # @param {type:\"string\"}"]},{"cell_type":"markdown","metadata":{"id":"qdTjmyvfZwar"},"source":["The code block below takes about **20** seconds to run when using the (1) **gemini-pro** model, (2) length of chunks is 512 and (3) maximum number of tokens is 550, but the actual time may vary depending on the condition of Colab and the status of the Google API."]},{"cell_type":"code","execution_count":78,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":233},"executionInfo":{"elapsed":8447,"status":"ok","timestamp":1720232367374,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"6x5fn6I-msGC","outputId":"afa91bae-64fd-4bdd-c1f8-36190fb62c1a"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------Final Summary----------------------------\n","\n","**摘要**  **段落 1：**學習需要實踐，通過動手做可以真正理解知識。  **段落 2：**困難的課程是學習機會，應專注於理解概念和培養思考能力。\n","**段落 3：**課外活動提供成長和快樂，任何帶來快樂的活動都可以被視為學習。  **段落\n","4：**課外活動培養團隊合作、領導力和溝通等軟實力，這些技能對電機工程師至關重要。  **段落\n","5：**軟實力是電機工程師成功的關鍵，應通過課外活動和學習機會培養這些能力。  **段落 6：**職業發展受實力、努力、大智和自我技能影響，並可能呈現不同模式。\n","**段落 7：**實力、努力和自我技能是職業發展的關鍵要素，設定長期的目標可以提供方向和激勵。  **段落\n","8：**長程目標應具有意義、可行、具體，並設定現實的時間框架。\n","\n","Length of final summary: 339\n","Time taken to generate the final summary: 8.25 sec.\n"]}],"source":["# Finally, we compile a final summary from the summaries of each section.\n","\n","# Record the start time.\n","start = time.time()\n","\n","# Run final summarization.\n","summarization_prompt = summarization_prompt_template.replace(\"<text>\", collected_summarization)\n","final_summarization = summarization(summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n","\n","# Calculate the execution time and round it to 2 decimal places.\n","cost_time = round(time.time() - start, 2)\n","\n","# Print the summary and its length.\n","print(f\"----------------------------Final Summary----------------------------\\n\")\n","for text in textwrap.wrap(final_summarization, 80):\n","        print(f\"{text}\")\n","print(f\"\\nLength of final summary: {len(final_summarization)}\")\n","print(f\"Time taken to generate the final summary: {cost_time} sec.\")"]},{"cell_type":"code","execution_count":79,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1720232367374,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"PPR2Am6omt0U","outputId":"18f5ebc0-234d-489d-fe7e-b58048e74ce1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Final summary has been saved to ./final-summary-信號與人生-gemini-multi-stage.txt\n"]}],"source":["''' In this block, you can modify your desired output path of final summary. '''\n","\n","output_path = f\"./final-summary-{suffix}-gemini-multi-stage.txt\"\n","\n","# If you need to convert Simplified Chinese to Traditional Chinese, please set this option to True; otherwise, set it to False.\n","convert_to_tradition_chinese = False\n","\n","if convert_to_tradition_chinese == True:\n","    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n","    cc = OpenCC('s2t')\n","    final_summarization = cc.convert(final_summarization)\n","\n","# Output your final summary\n","with open(output_path, \"w\") as fp:\n","    fp.write(final_summarization)\n","\n","print(f\"Final summary has been saved to {output_path}\")"]},{"cell_type":"markdown","metadata":{"id":"xDZVeHCKvcMy"},"source":["#### **If you want to use the method of Refinement, begin with this part.**\n","\n"]},{"cell_type":"code","execution_count":81,"metadata":{"executionInfo":{"elapsed":209,"status":"ok","timestamp":1720232381691,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"1goEansHvc8C"},"outputs":[],"source":["# @title Prompt Setting of Gemini Refinement { run: \"auto\" }\n","''' You can modify the summarization prompt and maximum number of tokens. '''\n","''' However, DO NOT modify the part of <text>.'''\n","\n","# We set the maximum number of tokens.\n","# @markdown **max_tokens**: We set the maximum number of tokens.\n","max_tokens = 550 # @param {type:\"integer\"}\n","\n","# @markdown ### Changing **summarization_prompt_template** and **summarization_prompt_refine_template**\n","# @markdown You can modify the summarization prompt and maximum number of tokens. However, **DO NOT** modify the part of `<text>`.\n","\n","# Initial prompt.\n","# @markdown **summarization_prompt_template**: Initial prompt.\n","summarization_prompt_template = \"請在 300 字以內，提供以下文字的簡潔摘要:<text>\" # @param {type:\"string\"}\n","\n","# Refinement prompt.\n","# @markdown **summarization_prompt_refinement_template**: Refinement prompt.\n","summarization_prompt_refinement_template = \"請在 500 字以內，結合原先的摘要和新的內容，提供簡潔的摘要:<text>\" # @param {type:\"string\"}"]},{"cell_type":"markdown","metadata":{"id":"K5AunhcUwDWh"},"source":["Pipeline of the method of Refinement.\n","\n","Step1: It starts by running a prompt on a small portion of the data, generating initial output.\n","\n","Step2: For each following document, the previous output is fed in along with the new document.\n","\n","Step3: The LLM is instructed to refine the output based on the new document's information.\n","\n","Step4: This process continues iteratively until all documents have been processed."]},{"cell_type":"markdown","metadata":{"id":"EJMgqTC_2WD0"},"source":["The code block below takes about **45** seconds to run when using the (1) **gemini-pro** model and (2) maximum number of tokens is 500, but the actual time may vary depending on the condition of Colab and the status of the Google API."]},{"cell_type":"code","execution_count":82,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":54725,"status":"ok","timestamp":1720232475408,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"DDWW_K4OwG1N","outputId":"85577210-3b68-4e8b-e914-0f5b4ed49884"},"outputs":[{"name":"stdout","output_type":"stream","text":["----------------------------Summary of Segment 1----------------------------\n","\n","「做出來的學問」強調學習需要實踐。光靠聽講或閱讀無法真正吸收知識。只有透過動手做，將所學整合應用於實際專案或任務中，才能將知識內化為自己的。這種實作過程有助於加\n","\n","深理解，並將學到的演算法或概念融會貫通。因此，學習過程中應積極參與動手實作，才能真正掌握學問。\n","\n","Length of summary for segment 1: 127\n","Time taken to generate summary for segment 1: 4.76 sec.\n","\n","----------------------------Summary of the First 2 Segments----------------------------\n","\n","**簡潔摘要**\n","\n","學習需要實踐，透過動手做才能真正吸收知識。實作過程有助於加深理解，將學到的演算法或概念融會貫通。因此，學習過程中應積極參與動手實作，才能真正掌握學問。\n","\n","然而，許多人認為實作不重要，甚至因此放棄修課。但實作正是學習的機會，可以學到最多。雖然實作可能很辛苦，但對全面學習很有幫助。\n","\n","在學習過程中，培養思考能力和習慣至關重要。最好的方法是讀書時思考數學式子和概念的意義。透過不斷思考，可以深入理解所學內容，並培養獨立思考的能力。\n","\n","Length of summary for the first 2 segments: 223\n","Time taken to generate summary for the first 2 segments: 5.79 sec.\n","\n","----------------------------Summary of the First 3 Segments----------------------------\n","\n","**簡潔摘要**  學習需要實踐，透過動手做才能真正吸收知識。實作有助於加深理解，培養思考能力。因此，學習過程中應積極參與動手實作，才能真正掌握學問。  學習不\n","\n","僅限於課業內，課業外也有許多值得學習的事物。只要能帶來增長、進步和快樂，任何活動都可以視為學習機會。例如，打球可以增進手腦協調和團隊精神，爬山可以培養毅力，旅行\n","\n","可以擴展見識。因此，應積極參與各種活動，將學習融入生活，全面提升自我。\n","\n","Length of summary for the first 3 segments: 195\n","Time taken to generate summary for the first 3 segments: 6.12 sec.\n","\n","----------------------------Summary of the First 4 Segments----------------------------\n","\n","**簡潔摘要**\n","\n","學習不僅限於課堂，更重要的是透過動手實作和參與各種活動來獲得。實作有助於加深理解和培養思考能力，而課外活動則能增進手腦協調、毅力、見識和人際互動。  談戀愛、交\n","\n","朋友和參與社團活動都是學習的機會，因為它們能讓我們體驗人與人之間的各種感覺、期待和溝通方式。電機系學生可以透過與同學交朋友、參加戲劇或電業活動來獲得成長和進步。\n","\n","因此，學習應融入生活，積極參與各種活動，才能全面提升自我。\n","\n","Length of summary for the first 4 segments: 201\n","Time taken to generate summary for the first 4 segments: 6.09 sec.\n","\n","----------------------------Summary of the First 5 Segments----------------------------\n","\n","**簡潔摘要**\n","\n","學習不僅限於課堂，更重要的是透過動手實作和參與各種活動來獲得。實作有助於加深理解和培養思考能力，而課外活動則能增進手腦協調、毅力、見識和人際互動。  談戀愛、交\n","\n","朋友和參與社團活動都是學習的機會，因為它們能讓我們體驗人與人之間的各種感覺、期待和溝通方式。電機系學生可以透過與同學交朋友、參加戲劇或電業活動來獲得成長和進步。\n","\n","此外，參與課外活動還能培養重要的軟實力，例如團隊合作、溝通和領導能力。這些軟實力對於在電機工程領域取得成功至關重要，因為很少有事情可以單獨完成。因此，積極參與各\n","\n","種活動，才能全面提升自我。\n","\n","Length of summary for the first 5 segments: 265\n","Time taken to generate summary for the first 5 segments: 6.34 sec.\n","\n","----------------------------Summary of the First 6 Segments----------------------------\n","\n","**簡潔摘要**  學習不僅限於課堂，實作和課外活動也至關重要。實作加深理解，培養思考能力，而課外活動增進手腦協調、毅力、見識和人際互動。\n","\n","談戀愛、交朋友和參與社團活動提供體驗人際關係的機會，培養溝通、協調和領導等軟實力。這些軟實力對於電機工程領域的成功至關重要，因為團隊合作和人際互動不可或缺。\n","\n","參與課外活動有助於塑造個人軟實力，而這些能力通常是透過努力培養而非天生的。電機工程師的成功往往歸功於他們出色的軟實力，這些能力是透過課外學習和成長機會獲得的。\n","\n","Length of summary for the first 6 segments: 230\n","Time taken to generate summary for the first 6 segments: 6.02 sec.\n","\n","----------------------------Summary of the First 7 Segments----------------------------\n","\n","**簡潔摘要**  學習不僅限於課堂，實作和課外活動對於全面發展至關重要。實作加深理解，培養思考能力，而課外活動增進手腦協調、毅力、見識和人際互動。  課外活動\n","\n","，如談戀愛、交朋友和參與社團，提供體驗人際關係的機會，培養溝通、協調和領導等軟實力。這些軟實力對於電機工程領域的成功至關重要，因為團隊合作和人際互動不可或缺。\n","\n","參與課外活動有助於塑造個人軟實力，這些能力通常是透過努力培養而非天生的。電機工程師的成功往往歸功於他們出色的軟實力，這些能力是透過課外學習和成長機會獲得的。\n","\n","此外，個人事業發展的黃金時期通常在 35 至 55 歲之間。影響事業發展的關鍵因素包括實力、努力、大智和自我技能。這些因素比學業成績更能影響個人事業的成功。\n","\n","Length of summary for the first 7 segments: 319\n","Time taken to generate summary for the first 7 segments: 6.88 sec.\n","\n","----------------------------Summary of the First 8 Segments----------------------------\n","\n","**簡潔摘要**  學習不僅限於課堂，實作和課外活動對於全面發展至關重要。實作加深理解，培養思考能力，而課外活動增進手腦協調、毅力、見識和人際互動。\n","\n","課外活動提供體驗人際關係的機會，培養溝通、協調和領導等軟實力，這些軟實力對於電機工程領域的成功至關重要。\n","\n","個人事業發展的關鍵因素包括實力（全面學習）、努力、大智和自我技能。這些因素比學業成績更能影響個人事業的成功。\n","\n","實力來自於全面的學習，努力是不可或缺的，自我技能則透過課外學習和成長機會獲得。個人可以設定長程目標，並透過這些因素的培養，提升個人發展和事業成功。\n","\n","Length of summary for the first 8 segments: 259\n","Time taken to generate summary for the first 8 segments: 6.52 sec.\n","\n","----------------------------Summary of the First 9 Segments----------------------------\n","\n","**簡潔摘要**  學習不僅限於課堂，實作和課外活動對於全面發展至關重要。實作加深理解，培養思考能力，而課外活動增進手腦協調、毅力、見識和人際互動。\n","\n","課外活動提供體驗人際關係的機會，培養溝通、協調和領導等軟實力，這些軟實力對於電機工程領域的成功至關重要。\n","\n","個人事業發展的關鍵因素包括實力（全面學習）、努力、大智和自我技能。這些因素比學業成績更能影響個人事業的成功。\n","\n","實力來自於全面的學習，努力是不可或缺的，自我技能則透過課外學習和成長機會獲得。個人可以設定長程目標，並透過這些因素的培養，提升個人發展和事業成功。\n","\n","長程目標是個人願意花費大量時間和精力去實現的目標，它能激勵個人向上衝刺。\n","\n","Length of summary for the first 9 segments: 297\n","Time taken to generate summary for the first 9 segments: 6.02 sec.\n","\n"]}],"source":["paragraph_summarizations = []\n","\n","# First, we summarize each section that has been split up separately.\n","for index, chunk in enumerate(chunks):\n","\n","    if index == 0:\n","        # Record the start time.\n","        start = time.time()\n","\n","        # Construct summarization prompt.\n","        summarization_prompt = summarization_prompt_template.replace(\"<text>\", chunk)\n","\n","        # Step1: It starts by running a prompt on a small portion of the data, generating initial output.\n","        first_paragraph_summarization = summarization(summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n","\n","        # Record the result.\n","        paragraph_summarizations.append(first_paragraph_summarization)\n","\n","        # Calculate the execution time and round it to 2 decimal places.\n","        cost_time = round(time.time() - start, 2)\n","\n","        # Print the summary and its length.\n","        print(f\"----------------------------Summary of Segment {index + 1}----------------------------\\n\")\n","        for text in textwrap.wrap(first_paragraph_summarization, 80):\n","            print(f\"{text}\\n\")\n","        print(f\"Length of summary for segment {index + 1}: {len(first_paragraph_summarization)}\")\n","        print(f\"Time taken to generate summary for segment {index + 1}: {cost_time} sec.\\n\")\n","\n","    else:\n","        # Record the start time.\n","        start = time.time()\n","\n","        # Step2: For each following document, the previous output is fed in along with the new document.\n","        chunk_text = f\"\"\"前 {index} 段的摘要: {paragraph_summarizations[-1]}\\n第 {index + 1} 段的內容: {chunk}\"\"\"\n","\n","        # Construct refinement prompt for summarization.\n","        summarization_prompt = summarization_prompt_refinement_template.replace(\"<text>\", chunk_text)\n","\n","        # Step3: The LLM is instructed to refine the output based on the new document's information.\n","        try:\n","          paragraph_summarization = summarization(summarization_prompt=summarization_prompt, model_name=model_name, temperature=temperature, top_p=top_p, max_tokens=max_tokens)\n","\n","          # Record the result.\n","          paragraph_summarizations.append(paragraph_summarization)\n","        except: continue\n","        # Calculate the execution time and round it to 2 decimal places.\n","        cost_time = round(time.time() - start, 2)\n","\n","        # print results.\n","        print(f\"----------------------------Summary of the First {index + 1} Segments----------------------------\\n\")\n","        for text in textwrap.wrap(paragraph_summarization, 80):\n","            print(f\"{text}\\n\")\n","        print(f\"Length of summary for the first {index + 1} segments: {len(paragraph_summarization)}\")\n","        print(f\"Time taken to generate summary for the first {index + 1} segments: {cost_time} sec.\\n\")\n","\n","    # Step4: This process continues iteratively until all documents have been processed."]},{"cell_type":"code","execution_count":83,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":204,"status":"ok","timestamp":1720232479924,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"t5jw0HwWwW83","outputId":"26a78076-1362-4935-bbeb-7bba069c6a6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Final summary has been saved to ./final-summary-信號與人生-gemini-refinement.txt\n","\n","===== Below is the final summary (297 words) =====\n","\n","**簡潔摘要**\n","學習不僅限於課堂，實作和課外活動對於全面發展至關重要。實作加深理解，培養思考能力，而課外活動增進手腦協調、毅力、見識和人際互動。\n","課外活動提供體驗人際關係的機會，培養溝通、協調和領導等軟實力，這些軟實力對於電機工程領域的成功至關重要。\n","個人事業發展的關鍵因素包括實力（全面學習）、努力、大智和自我技能。這些因素比學業成績更能影響個人事業的成功。  實力來自於全面的\n","學習，努力是不可或缺的，自我技能則透過課外學習和成長機會獲得。個人可以設定長程目標，並透過這些因素的培養，提升個人發展和事業成功\n","。  長程目標是個人願意花費大量時間和精力去實現的目標，它能激勵個人向上衝刺。\n"]}],"source":["''' In this block, you can modify your desired output path of final summary. '''\n","\n","output_path = f\"./final-summary-{suffix}-gemini-refinement.txt\"\n","\n","# If you need to convert Simplified Chinese to Traditional Chinese, please set this option to True; otherwise, set it to False.\n","convert_to_tradition_chinese = False\n","\n","if convert_to_tradition_chinese == True:\n","    # Creating an instance of OpenCC for Simplified to Traditional Chinese conversion.\n","    cc = OpenCC('s2t')\n","    paragraph_summarizations[-1] = cc.convert(paragraph_summarizations[-1])\n","\n","# Output your final summary\n","with open(output_path, \"w\") as fp:\n","    fp.write(paragraph_summarizations[-1])\n","\n","# Show the result.\n","print(f\"Final summary has been saved to {output_path}\")\n","print(f\"\\n===== Below is the final summary ({len(paragraph_summarizations[-1])} words) =====\\n\")\n","for text in textwrap.wrap(paragraph_summarizations[-1], 64):\n","    print(text)"]},{"cell_type":"markdown","metadata":{"id":"EtQoyYjfdQLC"},"source":["# Part5 - Check the correctness of the submission file\n"]},{"cell_type":"code","execution_count":84,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":228,"status":"ok","timestamp":1720232482522,"user":{"displayName":"Yizhou C","userId":"11899853813518570425"},"user_tz":240},"id":"Gclg3cORdiVR","outputId":"304e9290-3390-47be-e4ef-dbe2ff80e0f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Please save your submission file in JSON format.\n","The format of your submission file is wrong.\n","Please check the format of your submission file.\n"]}],"source":["# Check the correctness of the submission file.\n","import json\n","import re\n","\n","your_submission_path = \"YOUR_SUBMISSION_PATH\"\n","\n","def check_format(your_submission_path):\n","\n","    final_score = 0\n","\n","    # check the extension of the file.\n","    if not your_submission_path.endswith(\".json\"):\n","        print(\"Please save your submission file in JSON format.\")\n","        return False, final_score\n","    else:\n","        try:\n","            with open(your_submission_path, \"r\") as fp:\n","                your_submission = json.load(fp)\n","\n","            evaluation_result = your_submission[\"history\"][0][\"messages\"][1][\"content\"]\n","\n","            if \"總分：\" not in evaluation_result:\n","                # Correct format: 總分: <你的分數>\n","                print(\"Please make sure that the correct format of final score is included in the evaluation result.\")\n","                print(\"The correct format is 總分: <你的分數>. For example, 總分: 97\")\n","                return False, final_score\n","\n","            evaluation_result = evaluation_result.strip()\n","            score_pattern = r\"總分：\\d+\"\n","            score = re.findall(score_pattern, evaluation_result)\n","\n","            if score:\n","                final_score = score[-1].replace(\"總分：\", \"\")\n","                if \"/100\" in final_score:\n","                    final_score = final_score.replace(\"/100\", \"\")\n","            else:\n","                print(\"Please make sure that the final score is included in the evaluation result.\")\n","                return False, final_score\n","\n","        except:\n","            print(\"Open the file failed. Please check the file path or save your submission file in correct JSON format\")\n","            return False, final_score\n","\n","    return True, final_score\n","\n","format_correctness, final_score = check_format(your_submission_path)\n","if format_correctness== True:\n","    print(\"The format of your submission file is correct.\")\n","    print(f\"Your final score is {final_score}.\")\n","else:\n","    print(\"The format of your submission file is wrong.\")\n","    print(\"Please check the format of your submission file.\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["z9QC8lG_QRZL","hRzf_0cTV6TS","GEmYimdXxctB","eBI-Ba8QzLU8"],"gpuType":"T4","provenance":[{"file_id":"1Ysr25kz6lP7gR8DNTkJMAqOuMp2bhXes","timestamp":1720230380847}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0a46661e01c549a0a1ee63121cd01bb6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88dbe924dd564b32b6b282aa581d24e8","placeholder":"​","style":"IPY_MODEL_b6efa01705d7491a9cd7d9ff0868ec9c","value":"Generating test split: 100%"}},"0f06d752ff9e46e289f50ade0c5c4465":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13c8e2712bfd4dfaa359da46a1ccd9d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21715260b1154470820b63c3fad1e4f8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"298a20d5460445bcb4872fd1553e993d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45b0b5230ac444479157b04a351c1233":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48f6cc4b3f4340748ec19a59a0da2450":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_898b1317b7ae4932b865a19b53322e35","placeholder":"​","style":"IPY_MODEL_13c8e2712bfd4dfaa359da46a1ccd9d5","value":" 1/1 [00:00&lt;00:00,  9.72 examples/s]"}},"5089838937f6495a91dbe6059863ec63":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_90f0fa64343943d69a9ef53f266b3ae3","max":305,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61d9a406fb0243fe8097e47455866818","value":305}},"5156fd14f58644368b148f9c73fff9cd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f68c91877bff4a259be366636404eadf","IPY_MODEL_5089838937f6495a91dbe6059863ec63","IPY_MODEL_c513022c9c12401297db6554dd5eeb50"],"layout":"IPY_MODEL_7d46ac072d6c49ac950cdb58ec041ff4"}},"61d9a406fb0243fe8097e47455866818":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"636924e77e57421086b35f9b7f21ed5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a46661e01c549a0a1ee63121cd01bb6","IPY_MODEL_dc278d61129d415fbaabf02bfe42e17e","IPY_MODEL_48f6cc4b3f4340748ec19a59a0da2450"],"layout":"IPY_MODEL_21715260b1154470820b63c3fad1e4f8"}},"7c4aca1d686642f3811f3dfd56cbe540":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d46ac072d6c49ac950cdb58ec041ff4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eefe3fea7ae4de6915b903fafa082e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f8f4823e20747e790e43b435516d9df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_838bf0f29b244b55856d299bf93517f3","placeholder":"​","style":"IPY_MODEL_ccd92eb8d25b4b57a7faf2e7d9f5f182","value":" 3.14M/3.14M [00:00&lt;00:00, 4.98MB/s]"}},"838bf0f29b244b55856d299bf93517f3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"840eabcc6ad14ad9bfb0d792e7d85846":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"88dbe924dd564b32b6b282aa581d24e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"898b1317b7ae4932b865a19b53322e35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90f0fa64343943d69a9ef53f266b3ae3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"962ac1fb0ded40599389f65939df6e96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9b157dc60086447fb0ef5867d3323d65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b0cf8b957b4e489398311db291cea3bd","IPY_MODEL_e9717a562c2e4fb2ba8214be98b9dd3c","IPY_MODEL_7f8f4823e20747e790e43b435516d9df"],"layout":"IPY_MODEL_7eefe3fea7ae4de6915b903fafa082e0"}},"b0cf8b957b4e489398311db291cea3bd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_298a20d5460445bcb4872fd1553e993d","placeholder":"​","style":"IPY_MODEL_840eabcc6ad14ad9bfb0d792e7d85846","value":"Downloading data: 100%"}},"b6efa01705d7491a9cd7d9ff0868ec9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be333f52c13e4491a18154677a735937":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c513022c9c12401297db6554dd5eeb50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45b0b5230ac444479157b04a351c1233","placeholder":"​","style":"IPY_MODEL_0f06d752ff9e46e289f50ade0c5c4465","value":" 305/305 [00:00&lt;00:00, 5.83kB/s]"}},"ccd92eb8d25b4b57a7faf2e7d9f5f182":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8ba70dbc54a4959ac44edf58364f35b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc278d61129d415fbaabf02bfe42e17e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6702a21d61e478d920b5f4ed66e30a9","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8ba70dbc54a4959ac44edf58364f35b","value":1}},"e9717a562c2e4fb2ba8214be98b9dd3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_be333f52c13e4491a18154677a735937","max":3140168,"min":0,"orientation":"horizontal","style":"IPY_MODEL_962ac1fb0ded40599389f65939df6e96","value":3140168}},"f6702a21d61e478d920b5f4ed66e30a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f68c91877bff4a259be366636404eadf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c4aca1d686642f3811f3dfd56cbe540","placeholder":"​","style":"IPY_MODEL_fd9fac39c4cb496288dfd100de847d20","value":"Downloading readme: 100%"}},"fd9fac39c4cb496288dfd100de847d20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
